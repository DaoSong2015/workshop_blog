{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop Blog: 如何开发使用微信聊天机器人教程\n",
    "## Part 1: 问答机制(自动接收、回复消息。支持私信，群组，公众号等)\n",
    "* 文字的接收和发送/回复\n",
    "* 图片的接收和发送/回复\n",
    "* 文件的接收和发送/回复\n",
    "* 语音的接收和发送/回复\n",
    "\n",
    "\n",
    "## Part 2: 图像识别\n",
    "* 识别图片消息中的物体名字\n",
    "* 识别人脸\n",
    "\n",
    "## Part 3: 自然语言处理\n",
    "* 语音消息的识别，转换成文字\n",
    "* 消息文字转成语音\n",
    "* 消息的多语言互译\n",
    "\n",
    "\n",
    "<img src='http://www.kudosdata.com/wp-content/uploads/2016/11/cropped-KudosLogo1.png' width=30% style=\"float: right;\">\n",
    "### http://www.KudosData.com\n",
    "By: Sam.Gu@KudosData.com\n",
    "\n",
    "April, 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports 导入一些库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from __future__ import unicode_literals, division\n",
    "import time\n",
    "import datetime\n",
    "import itchat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itchat.logout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### can interupt and hot-login without re-scan QR code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itchat.auto_login(hotReload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itchat.search_friends(name='MicroscopeUser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<img id=\"qr\" src=\"QR2.png\" style=\"min-height:30px\" />\n",
    "<script>\n",
    "setInterval(function(){ \n",
    "    document.getElementById('qr').src=\"QR2.png?\"+Math.random()\n",
    "}, 5000);\n",
    "</script>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://itchat.readthedocs.io/zh/latest/tutorial/tutorial0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "一、课程介绍\n",
    "本文最佳阅读方式为实验楼的会员课程，建议点击链接在实验楼内阅读。\n",
    "\n",
    "1. 课程来源\n",
    "关于itchat进一步使用的问题你可以在主页加入官方交流群也可以在课程下面向我提问。\n",
    "\n",
    "课程在常见的三种系统中都可以进行操作，itchat建议使用可以安装的最新版本。\n",
    "\n",
    "本课程通过聊天机器人为例，介绍如何使用Python完成微信的点对点信息交互。\n",
    "\n",
    "2. 内容简介\n",
    "课程实现微信个人号聊天机器人\n",
    "通过自定义消息处理方法加入聊天功能\n",
    "3. 课程知识点\n",
    "本课程项目完成过程中将学习：\n",
    "\n",
    "微信消息的基本获取与处理\n",
    "微信消息的指定发送\n",
    "其中将重点介绍微信消息的获取与处理。\n",
    "\n",
    "二、实验环境\n",
    "在终端中输入以下命令，完成微信的API包itchat的安装。\n",
    "\n",
    "我们这里使用python3的环境（python2也是可行的）：\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四、实验步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itchat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@itchat.msg_register(itchat.content.TEXT)\n",
    "def print_content(msg):\n",
    "    print(msg['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# itchat.auto_login(enableCmdQR=-2, hotReload=True)\n",
    "itchat.auto_login(enableCmdQR=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itchat.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 实现微信消息的发送"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 获取自己的用户信息，返回自己的属性字典\n",
    "# itchat.search_friends()\n",
    "# 获取特定UserName的用户信息\n",
    "# itchat.search_friends(userName='@abcdefg1234567')\n",
    "# itchat.search_friends(userName=u'白黑')\n",
    "\n",
    "# 获取任何一项等于name键值的用户\n",
    "# itchat.search_friends(name=u'MicroscopeUser')\n",
    "\n",
    "# itchat.search_friends(name=u'郝素素')\n",
    "itchat.search_friends(name=u'白黑')\n",
    "# itchat.search_friends(name=u'TelescopeUser')\n",
    "\n",
    "# below are empty []\n",
    "# itchat.search_friends(wechatAccount=u'TelescopeUser')\n",
    "# itchat.search_friends(wechatAccount=u'白黑')\n",
    "\n",
    "\n",
    "# 获取分别对应相应键值的用户\n",
    "# itchat.search_friends(wechatAccount='littlecodersh')\n",
    "# 三、四项功能可以一同使用\n",
    "# itchat.search_friends(name='LittleCoder机器人', wechatAccount='littlecodersh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#coding=utf8\n",
    "# import itchat\n",
    "\n",
    "# itchat.auto_login(hotReload=True)\n",
    "\n",
    "# 注意实验楼环境的中文输入切换\n",
    "itchat.send(u'<程序自动发送> Timestamp:\\n{:%Y-%b-%d %H:%M:%S}\\n测试消息发送'.format(datetime.datetime.now()), 'filehelper')  \n",
    "itchat.send(u'<程序自动发送> Timestamp:\\n{:%Y-%b-%d %H:%M:%S}\\n测试消息发送'.format(datetime.datetime.now()), '@b572534cc72f93ddb08a55e861a12a4ee7ab4f3d645cc46643f846c319957b8e')  # hss\n",
    "itchat.send(u'<程序自动发送> Timestamp:\\n{:%Y-%b-%d %H:%M:%S}\\n测试消息发送'.format(datetime.datetime.now()), '@d2b2e81c90aebd98cd2f25d9b3598d77')  # TelescopeUser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@itchat.msg_register(itchat.content.TEXT)\n",
    "def print_content(msg):\n",
    "    return msg['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itchat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import itchat, time\n",
    "\n",
    "from itchat.content import *\n",
    "\n",
    "@itchat.msg_register([TEXT, MAP, CARD, NOTE, SHARING])\n",
    "def text_reply(msg):\n",
    "    itchat.send('%s: %s' % (msg['Type'], msg['Text']), msg['FromUserName'])\n",
    "\n",
    "@itchat.msg_register([PICTURE, RECORDING, ATTACHMENT, VIDEO])\n",
    "def download_files(msg):\n",
    "    msg['Text'](msg['FileName'])\n",
    "    return '@%s@%s' % ({'Picture': 'img', 'Video': 'vid'}.get(msg['Type'], 'fil'), msg['FileName'])\n",
    "\n",
    "@itchat.msg_register(FRIENDS)\n",
    "def add_friend(msg):\n",
    "    itchat.add_friend(**msg['Text']) # 该操作会自动将新好友的消息录入，不需要重载通讯录\n",
    "    itchat.send_msg('Nice to meet you!', msg['RecommendInfo']['UserName'])\n",
    "\n",
    "@itchat.msg_register(TEXT, isGroupChat=True)\n",
    "def text_reply(msg):\n",
    "    if msg['isAt']:\n",
    "        itchat.send(u'@%s\\u2005I received: %s' % (msg['ActualNickName'], msg['Content']), msg['FromUserName'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itchat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 实现最简单的与图灵机器人的交互"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "8edce3ce905a4c1dbb965e6b35c3834d\n",
    "\n",
    "\n",
    "eb720a8970964f3f855d863d24406576\n",
    "\n",
    "\n",
    "1107d5601866433dba9599fac1bc0083\n",
    "\n",
    "\n",
    "71f28bf79c820df10d39b4074345ef8c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#coding=utf8\n",
    "import requests\n",
    "\n",
    "apiUrl = 'http://www.tuling123.com/openapi/api'\n",
    "data = {\n",
    "    'key'    : '71f28bf79c820df10d39b4074345ef8c', # 如果这个Tuling Key不能用，那就换一个\n",
    "    'info'   : 'hello', # 这是我们发出去的消息\n",
    "    'userid' : 'wechat-robot', # 这里你想改什么都可以\n",
    "}\n",
    "# 我们通过如下命令发送一个post请求\n",
    "r = requests.post(apiUrl, data=data).json()\n",
    "\n",
    "# 让我们打印一下返回的值，看一下我们拿到了什么\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(u'\\u4eb2\\u7231\\u7684\\uff0c\\u5f53\\u5929\\u8bf7\\u6c42\\u6b21\\u6570\\u5df2\\u7528\\u5b8c\\u3002')\n",
    "# 亲爱的，当天请求次数已用完。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(u'\\u4f60\\u597d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 五、实验程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    }
   ],
   "source": [
    "#coding=utf8\n",
    "import requests\n",
    "import itchat\n",
    "\n",
    "KEY = '71f28bf79c820df10d39b4074345ef8c'\n",
    "\n",
    "'''\n",
    "8edce3ce905a4c1dbb965e6b35c3834d\n",
    "eb720a8970964f3f855d863d24406576\n",
    "1107d5601866433dba9599fac1bc0083\n",
    "71f28bf79c820df10d39b4074345ef8c\n",
    "'''\n",
    "\n",
    "def get_response(msg):\n",
    "    # 这里我们就像在“3. 实现最简单的与图灵机器人的交互”中做的一样\n",
    "    # 构造了要发送给服务器的数据\n",
    "    apiUrl = 'http://www.tuling123.com/openapi/api'\n",
    "    data = {\n",
    "        'key'    : KEY,\n",
    "        'info'   : msg,\n",
    "        'userid' : 'wechat-robot',\n",
    "    }\n",
    "    try:\n",
    "        r = requests.post(apiUrl, data=data).json()\n",
    "        # 字典的get方法在字典没有'text'值的时候会返回None而不会抛出异常\n",
    "        return r.get('text')\n",
    "    # 为了防止服务器没有正常响应导致程序异常退出，这里用try-except捕获了异常\n",
    "    # 如果服务器没能正常交互（返回非json或无法连接），那么就会进入下面的return\n",
    "    except:\n",
    "        # 将会返回一个None\n",
    "        return\n",
    "\n",
    "# 这里是我们在“1. 实现微信消息的获取”中已经用到过的同样的注册方法\n",
    "@itchat.msg_register(itchat.content.TEXT)\n",
    "def tuling_reply(msg):\n",
    "    # 为了保证在图灵Key出现问题的时候仍旧可以回复，这里设置一个默认回复\n",
    "    defaultReply = 'I received: ' + msg['Text']\n",
    "    # 如果图灵Key出现问题，那么reply将会是None\n",
    "    reply = get_response(msg['Text'])\n",
    "    # a or b的意思是，如果a有内容，那么返回a，否则返回b\n",
    "    # 有内容一般就是指非空或者非None，你可以用`if a: print('True')`来测试\n",
    "    return reply or defaultReply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 为了让实验过程更加方便（修改程序不用多次扫码），我们使用热启动\n",
    "itchat.auto_login(enableCmdQR=-2)\n",
    "# itchat.auto_login(hotReload=True, enableCmdQR=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itchat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# itchat.logout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sam: Adapted Turing reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#coding=utf8\n",
    "import itchat\n",
    "from itchat.content import *\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "KEY = '71f28bf79c820df10d39b4074345ef8c'\n",
    "\n",
    "'''\n",
    "8edce3ce905a4c1dbb965e6b35c3834d\n",
    "eb720a8970964f3f855d863d24406576\n",
    "1107d5601866433dba9599fac1bc0083\n",
    "71f28bf79c820df10d39b4074345ef8c\n",
    "'''\n",
    "\n",
    "def get_response(msg):\n",
    "    # 这里我们就像在“3. 实现最简单的与图灵机器人的交互”中做的一样\n",
    "    # 构造了要发送给服务器的数据\n",
    "    apiUrl = 'http://www.tuling123.com/openapi/api'\n",
    "    data = {\n",
    "        'key'    : KEY,\n",
    "        'info'   : msg,\n",
    "        'userid' : 'wechat-robot',\n",
    "    }\n",
    "    try:\n",
    "        r = requests.post(apiUrl, data=data).json()\n",
    "        # 字典的get方法在字典没有'text'值的时候会返回None而不会抛出异常\n",
    "        return r.get('text')\n",
    "    # 为了防止服务器没有正常响应导致程序异常退出，这里用try-except捕获了异常\n",
    "    # 如果服务器没能正常交互（返回非json或无法连接），那么就会进入下面的return\n",
    "    except:\n",
    "        # 将会返回一个None\n",
    "        return\n",
    "\n",
    "\n",
    "@itchat.msg_register([TEXT, MAP, CARD, NOTE, SHARING])\n",
    "def text_reply(msg):\n",
    "#     itchat.send('%s: %s' % (msg['Type'], msg['Text']), msg['FromUserName'])\n",
    "# def tuling_reply(msg):\n",
    "    # 为了保证在图灵Key出现问题的时候仍旧可以回复，这里设置一个默认回复\n",
    "    defaultReply = 'I received: ' + msg['Text']\n",
    "    # 如果图灵Key出现问题，那么reply将会是None\n",
    "    reply = get_response(msg['Text'])\n",
    "    # a or b的意思是，如果a有内容，那么返回a，否则返回b\n",
    "    # 有内容一般就是指非空或者非None，你可以用`if a: print('True')`来测试\n",
    "    return reply or defaultReply\n",
    "\n",
    "\n",
    "\n",
    "@itchat.msg_register([PICTURE, RECORDING, ATTACHMENT, VIDEO])\n",
    "def download_files(msg):\n",
    "    msg['Text'](msg['FileName'])\n",
    "    return '@%s@%s' % ({'Picture': 'img', 'Video': 'vid'}.get(msg['Type'], 'fil'), msg['FileName'])\n",
    "\n",
    "@itchat.msg_register(FRIENDS)\n",
    "def add_friend(msg):\n",
    "    itchat.add_friend(**msg['Text']) # 该操作会自动将新好友的消息录入，不需要重载通讯录\n",
    "    itchat.send_msg('Nice to meet you!', msg['RecommendInfo']['UserName'])\n",
    "\n",
    "@itchat.msg_register(TEXT, isGroupChat=True)\n",
    "def text_reply(msg):\n",
    "    if msg['isAt']:\n",
    "#         itchat.send(u'@%s\\u2005I received: %s' % (msg['ActualNickName'], msg['Content']), msg['FromUserName'])\n",
    "        # 为了保证在图灵Key出现问题的时候仍旧可以回复，这里设置一个默认回复\n",
    "        defaultReply = 'I received: ' + msg['Text']\n",
    "        # 如果图灵Key出现问题，那么reply将会是None\n",
    "        reply = get_response(msg['Text'])\n",
    "        # a or b的意思是，如果a有内容，那么返回a，否则返回b\n",
    "        # 有内容一般就是指非空或者非None，你可以用`if a: print('True')`来测试\n",
    "        return reply or defaultReply\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# itchat.auto_login(True)\n",
    "itchat.auto_login(enableCmdQR=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itchat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<img id=\"qr\" src=\"QR2.png\" style=\"max-height:300px\" />\n",
    "<script>\n",
    "setInterval(function(){ \n",
    "    document.getElementById('qr').src=\"QR2.png?\"+Math.random()\n",
    "}, 5000);\n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ping 8.8.8.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 获取自己的用户信息，返回自己的属性字典\n",
    "# itchat.search_friends()\n",
    "# 获取特定UserName的用户信息\n",
    "# itchat.search_friends(userName='@abcdefg1234567')\n",
    "# 获取任何一项等于name键值的用户\n",
    "# itchat.search_friends(name=u'MicroscopeUser')\n",
    "itchat.search_friends(name=u'白黑')\n",
    "# itchat.search_friends(name=u'白黑')\n",
    "# itchat.search_friends(name=u'TelescopeUser')\n",
    "\n",
    "# 获取分别对应相应键值的用户\n",
    "# itchat.search_friends(wechatAccount='littlecodersh')\n",
    "# 三、四项功能可以一同使用\n",
    "# itchat.search_friends(name='LittleCoder机器人', wechatAccount='littlecodersh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 搜索好友名称\n",
    "# my_friend = bot.friends().search('白黑')[0]\n",
    "# my_friend = bot.friends().search('MicroscopeUser')[0]\n",
    "# my_friend = bot.friends().search('酷豆')[0]\n",
    "my_friend = bot.groups().search('Group酷豆')[0]\n",
    "my_friend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# my_friend.send('<程序自动发送>\\n<第%d条，共%d条>\\n%s' % (1, len(df_article['sentence']), df_article['sentence'][100]))\n",
    "# my_friend.send('<程序自动发送>\\n恭喜恭喜！\\n红包拿来~')\n",
    "my_friend.send('<程序自动发送> Timestamp:\\n{:%Y-%b-%d %H:%M:%S}\\n恭喜恭喜！\\n红包拿来~'.format(datetime.datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 发送文本给好友\n",
    "count = len(df_article['sentence'])\n",
    "# count = 5\n",
    "for i in range(729, count):\n",
    "    try:\n",
    "        my_friend.send('<第%d条，共%d条>\\n%s' % (i+1, count, df_article['sentence'][i]))\n",
    "        print ('success rec_id = %d' % (i+1))\n",
    "        time.sleep(np.random.randint(low = 5, high = 20))\n",
    "    except:\n",
    "        tmp_rand_int = np.random.randint(low = 70, high = 130)\n",
    "        print ('retry   rec_id = %d, after %d seconds... ' % (i+1, tmp_rand_int))\n",
    "        time.sleep(tmp_rand_int)\n",
    "        try:\n",
    "            my_friend.send('<第%d条，共%d条>\\n%s' % (i+1, count, df_article['sentence'][i]))\n",
    "            print ('success rec_id = %d' % (i+1))\n",
    "            time.sleep(np.random.randint(low = 5, high = 20))\n",
    "        except:\n",
    "            tmp_rand_int = np.random.randint(low = 70, high = 130)\n",
    "            print ('retry   rec_id = %d, after %d seconds... ' % (i+1, tmp_rand_int))\n",
    "            time.sleep(tmp_rand_int)\n",
    "            my_friend.send('<第%d条，共%d条>\\n%s' % (i+1, count, df_article['sentence'][i]))\n",
    "            print ('success rec_id = %d' % (i+1))\n",
    "            time.sleep(np.random.randint(low = 5, high = 20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib\n",
    "# Force matplotlib to not use any Xwindows backend.\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# img=\n",
    "imgplot = plt.imshow(mpimg.imread('QR.png'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgplot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# img=\n",
    "plt.imshow(mpimg.imread('QR.png'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib\n",
    "# Force matplotlib to not use any Xwindows backend.\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# img=\n",
    "imgplot = plt.imshow(mpimg.imread('QR.png'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgplot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# img=\n",
    "plt.imshow(mpimg.imread('QR.png'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import io\n",
    "# 中文字符和语言处理库\n",
    "import jieba\n",
    "# 机器学习库 sklearn 分类学习模型库\n",
    "from sklearn.feature_extraction import DictVectorizer # 数据结构变换：把 Dict 转换为 稀疏矩阵\n",
    "# 中文显示设置\n",
    "# from pylab import *  \n",
    "# mpl.rcParams['font.sans-serif'] = ['SimHei'] # 指定默认字体  \n",
    "# mpl.rcParams['axes.unicode_minus'] = False # 解决保存图像是负号'-'显示为方块的问题 \n",
    "# mpl.rcParams['font.size'] = 14 # 设置字体大小\n",
    "np.random.seed(88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from wxpy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python3\n",
    "# 中文分词功能小函数， 输出 字符串， 各词组由空格分隔\n",
    "def KudosData_word_tokenizer(foo):\n",
    "    # remove lead & tail spaces firstly:\n",
    "    foo = foo.strip()\n",
    "    seg_token = jieba.cut(str(foo), cut_all=True)\n",
    "    seg_str = str(' '.join(seg_token)).strip()\n",
    "\n",
    "    return seg_str\n",
    "# Python2\n",
    "# 中文分词功能小函数， 输出 字符串， 各词组由空格分隔\n",
    "# def KudosData_word_tokenizer(foo):\n",
    "#     seg_token = jieba.cut(foo, cut_all=True)\n",
    "#     seg_str = ' '.join(seg_token)\n",
    "#     return seg_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python3\n",
    "# 中文分词功能小函数， 输出 字符串， 各词组由空格分隔\n",
    "def KudosData_word_count(foo):\n",
    "    # remove lead & tail spaces firstly:\n",
    "    foo = foo.strip()\n",
    "    seg_token = jieba.cut(str(foo), cut_all=True)\n",
    "    seg_str = str(' '.join(seg_token)).strip()\n",
    "    seg_count = pd.value_counts(str(seg_str).lower().split(' '))\n",
    "    seg_count = seg_count.to_dict() \n",
    "    seg_count.pop('', None) # remove EMPTY dict key: ''\n",
    "#     输出 dictionary： { key 词组， value 计数 }\n",
    "    #     return seg_count.to_dict()\n",
    "    return seg_count\n",
    "\n",
    "# Python2\n",
    "# 中文分词功能小函数， 输出 dictionary： { key 词组， value 计数 }\n",
    "# def KudosData_word_count(foo):\n",
    "#     seg_token = jieba.cut(foo, cut_all=True)\n",
    "#     seg_str = '^'.join(seg_token)\n",
    "#     seg_count = pd.value_counts(seg_str.lower().split('^'))\n",
    "#     return seg_count.to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process Unicode text input\n",
    "with io.open('input_text.txt','r',encoding='utf8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "title = '''\n",
    "<Dummy Title>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_sentence(text):\n",
    "#     sentence = re.sub(r'\\W+', '#', sentence)\n",
    "    text = re.sub(r'\\t+', '', text) # remove one or more Tab\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linebreak_conversion_win_linux(text):\n",
    "    text = re.sub(r'\\r', '', text) # remove one or more Windows-line-break\n",
    "    text = re.sub(r'\\u3000', ' ', text) # convert white space: \\u3000    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_some_whitespace_1(text): # Does not remove normal Space\n",
    "#     sentence = re.sub(r'\\W+', '#', sentence)\n",
    "    text = re.sub(r'\\t+', '', text) # remove one or more Tab\n",
    "    text = re.sub(r'\\f+', '', text) # remove one or more special Space\n",
    "    text = re.sub(r'\\v+', '', text) # remove one or more special Space\n",
    "    text = re.sub(r' +', ' ', text) # merge two or more Spaces to 1 Space\n",
    "    \n",
    "    # remove lead & tail spaces:\n",
    "    text =text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_some_whitespace_2(text): # Does not remove normal Space\n",
    "#     sentence = re.sub(r'\\W+', '#', sentence)\n",
    "    text = re.sub(r'\\n+', ' ', text) # Change one or more \\n to a Space, this is to merge sentences within paragraph\n",
    "    text = re.sub(r' +', ' ', text) # merge two or more Spaces to 1 Space\n",
    "    text = re.sub(r'(\\^\\*\\#)( +)(\\#\\*\\^)', '^*##*^', text) # remove one or more Spaces between Paragraph-Tags or Sentence-Tags\n",
    "    \n",
    "    text = re.sub(r'(\\#\\*\\^S\\^\\*\\#)+', '#*^S^*#', text) # merge two or more sentence-Tags -> 1 Sentence-Tag\n",
    "    text = re.sub(r'(\\#\\*\\^P\\^\\*\\#)+', '#*^P^*#', text) # merge two or more Paragraph-Tags -> 1 Paragraph-Tag\n",
    "    \n",
    "    # remove a Sentence-Tag immediately before a Paragraph-Tag\n",
    "    text = re.sub(r'(\\#\\*\\^S\\^\\*\\#)( *)(\\#\\*\\^P\\^\\*\\#)', '#*^P^*#', text) \n",
    "\n",
    "    # remove lead & tail spaces:\n",
    "    text =text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Define Paragraph-Tag =  \n",
    "#   #*^P^*#\n",
    "\n",
    "### Define Sentence-Tag =  \n",
    "#   #*^S^*#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add a special tag to end of each paragraph\n",
    "def tag_paragraph(text):\n",
    "    text = re.sub(r'((\\n ) +)+', '#*^P^*#', text) # Tag paragraph, pattern: \\n + two or more Spaces\n",
    "    text = re.sub(r'((\\n\\t) +)+', '#*^P^*#', text) # Tag paragraph, pattern: \\n + two or more Tabs\n",
    "    text = re.sub(r'(\\n( *)\\n)+', '#*^P^*#', text) # Tag paragraph, pattern: \\n + zero or more Spaces + \\n\n",
    "    text = re.sub(r'(\\#\\*\\^P\\^\\*\\#)+', '#*^P^*#', text) # merge two or more Paragraph-Tags -> 1 Paragraph-Tag\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add a special tag to end of each sentence\n",
    "def tag_sentence(text):\n",
    "    text = re.sub(r'。+', '。#*^S^*#', text) # Tag sentence - Chinese\n",
    "    text = re.sub(r'！+', '！#*^S^*#', text) # Tag sentence - Chinese\n",
    "    text = re.sub(r'\\？+', '？#*^S^*#', text) # Tag sentence - Chinese\n",
    "#     text = re.sub(r'；+', '；#*^S^*#', text) # Tag sentence - Chinese\n",
    "\n",
    "    # 2017 MAR 24\n",
    "    text = re.sub(r'(\\.)( +)', '.#*^S^*#', text) # Tag sentence - English\n",
    "    text = re.sub(r'(!)( +)', '!#*^S^*#', text) # Tag sentence - English\n",
    "    text = re.sub(r'\\?( +)', '?#*^S^*#', text) # Tag sentence - English\n",
    "#     text = re.sub(r'(;)( +)', ';#*^S^*#', text) # Tag sentence - English\n",
    "\n",
    "    text = re.sub(r'\\.\\n', '.#*^S^*#', text) # Tag sentence - English\n",
    "    text = re.sub(r'!\\n', '!#*^S^*#', text) # Tag sentence - English\n",
    "    text = re.sub(r'\\?\\n', '?#*^S^*#', text) # Tag sentence - English\n",
    "#     text = re.sub(r';\\n', ';#*^S^*#', text) # Tag sentence - English\n",
    "    \n",
    "    # remove a Sentence-Tag immediately before an ending quotation\n",
    "    text = re.sub(r'\\#\\*\\^S\\^\\*\\#’', '’#*^S^*#', text) # Chinese ’\n",
    "    text = re.sub(r'\\#\\*\\^S\\^\\*\\#”', '”#*^S^*#', text) # Chinese ”\n",
    "    text = re.sub(r'\\#\\*\\^S\\^\\*\\#\\'', '\\'#*^S^*#', text) # English '\n",
    "    text = re.sub(r'\\#\\*\\^S\\^\\*\\#\"', '\"#*^S^*#', text) # English \"\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start tagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content_format = linebreak_conversion_win_linux(content)\n",
    "# content_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content_format = tag_paragraph(content_format)\n",
    "# content_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(content_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content_format = clean_some_whitespace_1(content_format)\n",
    "# content_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(content_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content_format = tag_sentence(content_format)\n",
    "# content_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(content_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content_format = clean_some_whitespace_2(content_format)\n",
    "# content_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(content_format))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Transfer tagged text to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split a text into paragraphs\n",
    "def split_article_to_paragraphs(text):\n",
    "#     text = text.replace(\"#*^P^*#\", \"#*^S^*#\") # convert Paragraph-Tag        \n",
    "    return text.split(\"#*^P^*#\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split a paragraph into sentences\n",
    "def split_paragraph_to_sentences(text):\n",
    "#     text = text.replace(\"#*^P^*#\", \"#*^S^*#\") # convert Paragraph-Tag        \n",
    "    return text.split(\"#*^S^*#\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1st loop Paragraphs list, 2nd loop Sentences list\n",
    "# create a few new columns, then write into dataframe, together with original Sentence string\n",
    "\n",
    "# define empty dataframe:\n",
    "df_article = pd.DataFrame(columns=('sentence', \n",
    "                                   'word_count', # sentence word count, including punctuations \n",
    "                                   'sentence_id', # unique sentence s/n within an article\n",
    "                                   'sentence_id_paragraph',  # sentence s/n within a paragraph \n",
    "                                   'paragraph_id', \n",
    "                                   'class_rank', \n",
    "                                   'score_word', # score based on word tf-idf\n",
    "                                   'score_sentence', # score based on intersection of sentence pairs\n",
    "                                   'score_word_norm', # Normalized score\n",
    "                                   'score_sentence_norm', # Normalized score\n",
    "                                   'score',\n",
    "                                  ))\n",
    "df_sentence_id = 0\n",
    "\n",
    "# split_article_to_paragraphs:\n",
    "article_paragraphs = split_article_to_paragraphs(content_format)\n",
    "\n",
    "for i in range(0, len(article_paragraphs)):\n",
    "    # split_paragraph_to_sentences:\n",
    "    article_paragraphs_sentences = split_paragraph_to_sentences(article_paragraphs[i].strip())\n",
    "\n",
    "    for j in range(0, len(article_paragraphs_sentences)):\n",
    "        if article_paragraphs_sentences[j].strip() != '':\n",
    "            df_sentence_id = df_sentence_id + 1\n",
    "            # write to dataframe:\n",
    "            df_article.loc[len(df_article)] = [article_paragraphs_sentences[j].strip(), \n",
    "                                               len(article_paragraphs_sentences[j].strip()), \n",
    "                                               df_sentence_id, \n",
    "                                               j+1, \n",
    "                                               i+1, \n",
    "                                               '', \n",
    "                                               '', \n",
    "                                               '', \n",
    "                                               '', \n",
    "                                               '', \n",
    "                                               '']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assume the 1st sentence as Title of Article\n",
    "\n",
    "title = df_article['sentence'][0]\n",
    "print('Title of Article : %s' % title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_article['sentence'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# KudosData_word_tokenizer\n",
    "df_article['sentence_tokenized'] = df_article['sentence'].apply(lambda x: KudosData_word_tokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make sure no empty sentences:\n",
    "print('Number of empty sentences in dataframe: %d ' % len(df_article[df_article['sentence_tokenized'] == '']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove invalid empty sentences\n",
    "print(len(df_article))\n",
    "df_article=df_article[df_article['sentence_tokenized'] != '']\n",
    "df_article = df_article.sort_values(by=['sentence_id'],).reset_index(drop=True)\n",
    "print(len(df_article))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KudosData_word_count\n",
    "df_article['sentence_tf'] = df_article['sentence'].apply(lambda x: KudosData_word_count(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = df_article['sentence_tokenized']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# my_stopword_list = ['and','to','the','of', 'in']\n",
    "#vectorizer = TfidfVectorizer(stop_words=my_stopword_list)\n",
    "\n",
    "# choice of no nomalization of tfidf output (not recommended)\n",
    "#vectorizer = TfidfVectorizer(norm=None)\n",
    "\n",
    "# TF-IDF score\n",
    "tfidf = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# IDF score\n",
    "idf_dict = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "\n",
    "# TF is in df_article[['sentence_tf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 把TF-iDF数值赋予相对应的词组\n",
    "tfidf = tfidf.tocsr()\n",
    "\n",
    "n_docs = tfidf.shape[0]\n",
    "tfidftables = [{} for _ in range(n_docs)]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i, j in zip(*tfidf.nonzero()):\n",
    "    tfidftables[i][terms[j]] = tfidf[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Document-Term-Matrix's TF-IDF matrix size:\n",
    "print ('This tfidf matrix is a very large table: [ %d rows/docs X %d columns/words ]' \n",
    "       % (tfidf.shape[0], tfidf.shape[1]))\n",
    "print ('It contains %d eliments: one score per word per document !'\n",
    "       % (tfidf.shape[0] * tfidf.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add tfidf score into dataframe \n",
    "df_article['tfidf'] = tfidftables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df_article[['sentence', 'sentence_tokenized', 'sentence_tf', 'tfidf']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate importance score for each sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring (1)\n",
    "### Calculate score_word for each sentence, based on sentence word_count tf-idf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# experiment: use tf-idf and len(sentence_tokenized) to calculate score\n",
    "# tmp_mean = tmp_sum / len(df_article['sentence_tokenized'][i])\n",
    "\n",
    "for i in range(0,len(df_article)):\n",
    "    if len(df_article['tfidf'][i]) == 0:\n",
    "        df_article['score_word'][i] = 0\n",
    "    else:\n",
    "        tmp_sum = 0\n",
    "        for key, values in df_article['tfidf'][i].items():\n",
    "            tmp_sum += values\n",
    "        \n",
    "        tmp_mean = tmp_sum / len(df_article['sentence_tokenized'][i])\n",
    "        df_article['score_word'][i] = tmp_mean \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring (2)\n",
    "### Calculate score_sentence for each sentence, based on pair-wise sentence comparison/intersection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Caculate raw intersection score between pair of two sentences, from df_article['sentence_tokenized']\n",
    "def sentences_intersection(sent1tokenized, sent2tokenized):\n",
    "    # www.KudosData.com - Chinese\n",
    "    # split the sentence into words/tokens\n",
    "    s1 = set(sent1tokenized.split(\" \"))\n",
    "    s2 = set(sent2tokenized.split(\" \"))\n",
    "\n",
    "    # If there is not intersection, just return 0\n",
    "    if (len(s1) + len(s2)) == 0:\n",
    "        print('# If there is not intersection, just return 0')\n",
    "        return 0\n",
    "\n",
    "    # Normalize the result by the average number of words\n",
    "    return len(s1.intersection(s2)) / ((len(s1) + len(s2)) / 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below step runs long time... Tuning needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate important score of every pair of sentences\n",
    "\n",
    "n = len(df_article['sentence_tokenized'])\n",
    "        \n",
    "# [Sam python 2.7 -> 3.4] values = [[0 for x in xrange(n)] for x in xrange(n)]\n",
    "df_score_raw_values = [[0 for x in range(n)] for x in range(n)]\n",
    "for i in range(0, n):\n",
    "    for j in range(0, n):\n",
    "        df_score_raw_values[i][j] = sentences_intersection(df_article['sentence_tokenized'][i], \n",
    "                                                           df_article['sentence_tokenized'][j])\n",
    "\n",
    "# The score of a sentence is the sum of all its intersection\n",
    "sentences_dic = {}\n",
    "\n",
    "for i in range(0, n):\n",
    "    df_score = 0\n",
    "    for j in range(0, n):\n",
    "        if i == j:\n",
    "            continue\n",
    "        df_score += df_score_raw_values[i][j]\n",
    "    df_article['score_sentence'][i] = df_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Data (Internal use,  not for production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 图表显示：\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.title(u'图')  \n",
    "plt.xlabel(u'X坐标：Sentence word_count')  \n",
    "plt.ylabel(u'Y坐标：Sentence frequency')  \n",
    "# df_article['word_count'].value_counts().sort_values(ascending=False).plot(kind='bar', color='green')\n",
    "df_article['word_count'].hist(bins=100)\n",
    "# plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 图表显示：\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.title(u'图')  \n",
    "plt.xlabel(u'X坐标：Paragraph_id')  \n",
    "plt.ylabel(u'Y坐标：Sentence frequency')  \n",
    "df_article['paragraph_id'].hist(bins=100)\n",
    "# plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 图表显示：\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.title(u'图')  \n",
    "plt.xlabel(u'X坐标：sentence_id_paragraph')  \n",
    "plt.ylabel(u'Y坐标：Sentence frequency')  \n",
    "df_article['sentence_id_paragraph'].hist(bins=100)\n",
    "# plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 图表显示：\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.title(u'图')  \n",
    "plt.xlabel(u'X坐标：score_word')  \n",
    "plt.ylabel(u'Y坐标：frequency')  \n",
    "df_article['score_word'].hist(bins = 100)\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "#plt.xlim(0,0.5)\n",
    "#plt.ylim(0,0.5)\n",
    "# plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 图表显示：\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.title(u'图')  \n",
    "plt.xlabel(u'X坐标：score_sentence')  \n",
    "plt.ylabel(u'Y坐标：frequency')  \n",
    "df_article['score_sentence'].hist(bins = 100)\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "#plt.xlim(0,0.5)\n",
    "#plt.ylim(0,0.5)\n",
    "# plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_article[(df_article['score_word'] > 0.15) & (df_article['score_word'] < 0.25)]\n",
    "# df_article[(df_article['score_word'] > 0.2)].sort_values(by=['score_sentence', 'score_word'], ascending=[False, False,])\n",
    "# df_article[(df_article['score_sentence'] > 250)].sort_values(by=['score_word', 'score_sentence'], ascending=[False, False,])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# log(score_word)\n",
    "df_article['score_word_log'] = np.log(df_article['score_word'].astype('float64') + \n",
    "                                      df_article[df_article['score_word'] >0 ]['score_word'].min()/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize score_word_log - Zero mean, unit variance\n",
    "\n",
    "# df_article['score_word_norm'] = (df_article['score_word'] - df_article['score_word'].mean()) / df_article['score_word'].std()\n",
    "df_article['score_word_norm'] = (df_article['score_word_log'] - df_article['score_word_log'].mean()) / df_article['score_word_log'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_article['score_word_norm'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize score_sentence - Zero mean, unit variance\n",
    "\n",
    "df_article['score_sentence_norm'] = (df_article['score_sentence'] - df_article['score_sentence'].mean()) / df_article['score_sentence'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_article['score_sentence_norm'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate class_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Score integration\n",
    "# df_article['score'] = (df_article['score_sentence_norm'] + df_article['score_word_norm']) / 2\n",
    "\n",
    "# Sam Gu: 23 Mar 2017 - Experiment found that the score_word, which is based on tf-idf, doesn't seem to work well.\n",
    "#                       score_word     tends to favor short sentences\n",
    "#                       score_sentence tends to favor long  sentences\n",
    "#                       Hence, here we use score_sentence only for final scoring.\n",
    "\n",
    "# df_article['score'] = (df_article['score_word'] + df_article['score_sentence'] ) / 2\n",
    "df_article['score'] = df_article['score_sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Min-Max normalization:\n",
    "df_article['score'] = (df_article['score'] - df_article['score'].min()) / (df_article['score'].max() -df_article['score'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_article['score'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sort firstly\n",
    "df_article = df_article.sort_values(by=['paragraph_id', 'score'], ascending=[True, False]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below step runs long time... Tuning needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate Class_Rank\n",
    "\n",
    "current_class_rank = 0\n",
    "current_paragraph_id = 0\n",
    "\n",
    "for i in range(0, len(df_article)):\n",
    "    if df_article['paragraph_id'][i] != current_paragraph_id: # change of Paragraph, thus reset class_rank\n",
    "        current_class_rank = 1\n",
    "        current_paragraph_id = df_article['paragraph_id'][i]\n",
    "    else:\n",
    "        current_class_rank = current_class_rank + 1\n",
    "        \n",
    "    df_article['class_rank'][i] = current_class_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sort Dataframe to 'result lookup mode'\n",
    "df_article = df_article.sort_values(by=['class_rank', 'score', 'paragraph_id', 'sentence_id'], \n",
    "                                    ascending=[True, False, True, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_article[['sentence',\n",
    "           'paragraph_id',\n",
    "           'sentence_id_paragraph',\n",
    "           'class_rank',\n",
    "           'score',\n",
    "           'sentence_tokenized'\n",
    "          ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df_article[(df_article['score'] == 0) | (df_article['score'] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract results based on user parameters:\n",
    "* Max number of words\n",
    "* % of original number of words\n",
    "* Max lines of sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a dataframe copy\n",
    "# Currently, the two dataframes are exactly the same.\n",
    "df_article_internal = pd.DataFrame.copy(df_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_words_original_article = df_article['sentence'].map(len).sum()\n",
    "total_words_internal_article = df_article_internal['sentence'].map(len).sum()\n",
    "# total_words_article_summary  = df_article_final['sentence'].map(len).sum()\n",
    "\n",
    "# print('total_words_original_article : ', total_words_original_article)\n",
    "# print('total_words_internal_article : ', total_words_internal_article)\n",
    "# print('total_words_article_summary  : ', total_words_article_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sam Gu: experiment shows no major improvement to use code in this block:\n",
    "\n",
    "'''\n",
    "\n",
    "# Heuristic cleaning:\n",
    "# 1.Remove sentences, which has only one valid word. \n",
    "# 2.Remove paragraph, which has only single sentence.\n",
    "\n",
    "# 1.\n",
    "df_article_internal = df_article_internal[df_article_internal['sentence_tokenized'].map(len) > 1]\n",
    "print('*** www.KudosData.com *** Removed number of sentences, which has only one valid word : %d'\n",
    "      % (len(df_article) - len(df_article_internal)))\n",
    "\n",
    "# 2.\n",
    "df_article_internal_paragraph = df_article_internal['paragraph_id'].value_counts().to_frame(name = 'sentence_count')\n",
    "df_article_internal_paragraph = df_article_internal_paragraph[df_article_internal_paragraph['sentence_count'] > 1]\n",
    "valid_paragraph_id = df_article_internal_paragraph.index.tolist()\n",
    "df_article_internal = df_article_internal[df_article_internal['paragraph_id'].isin(valid_paragraph_id)] \n",
    "print('*** www.KudosData.com *** Removed number of sentences in total : %d' % (len(df_article) - len(df_article_internal)))\n",
    "\n",
    "# sort Dataframe to 'result lookup mode'\n",
    "df_article_internal = df_article_internal.sort_values(by=['class_rank', 'score', 'paragraph_id', 'sentence_id'], \n",
    "                                    ascending=[True, False, True, True]).reset_index(drop=True)\n",
    "# Above sort a must sort !!! for below processing:\n",
    "# Loop Dataframe, accumulate length of sentences, stop when parm_max_word reached, return the index(), cut dataframe to display\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Accept user parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# valid range: >= 0\n",
    "parm_max_word = 200\n",
    "\n",
    "# valid range: >= 0\n",
    "parm_max_sentence = 10\n",
    "\n",
    "# valid range: [0, 100%]\n",
    "parm_max_percent = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Validation of user parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (isinstance(parm_max_word, int) | isinstance(parm_max_word, float)):\n",
    "    if parm_max_word >= 0:\n",
    "        print('!1! valid input parm_max_word : ', parm_max_word)\n",
    "    else:\n",
    "        print('!2! Invalid input parm_max_word : ', parm_max_word)    \n",
    "else:\n",
    "    print('!3! Invalid input parm_max_word : ', parm_max_word)\n",
    "\n",
    "if (isinstance(parm_max_sentence, int) | isinstance(parm_max_sentence, float)):\n",
    "    if parm_max_sentence >= 0:\n",
    "        print('!1! valid input parm_max_sentence : ', parm_max_sentence)\n",
    "    else:\n",
    "        print('!2! Invalid input parm_max_sentence : ', parm_max_sentence)    \n",
    "else:\n",
    "    print('!3! Invalid input parm_max_sentence : ', parm_max_sentence)\n",
    "\n",
    "if (isinstance(parm_max_percent, int) | isinstance(parm_max_percent, float)):\n",
    "    if parm_max_percent >= 0:\n",
    "        print('!1! valid input parm_max_percent : ', parm_max_percent)\n",
    "    else:\n",
    "        print('!2! Invalid input parm_max_percent : ', parm_max_percent)    \n",
    "else:\n",
    "    print('!3! Invalid input parm_max_percent : ', parm_max_percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cut by parm_max_percent\n",
    "\n",
    "# Loop Dataframe, accumulate length of sentences, stop when parm_max_word reached, return the index(), cut dataframe to display\n",
    "\n",
    "sum_current_word = 0\n",
    "cut_index = len(df_article_internal['sentence'])\n",
    "\n",
    "# print('Start loop...')\n",
    "for s in range(0, len(df_article_internal['sentence'])):\n",
    "#     print('s : %d' % s)\n",
    "    if sum_current_word / total_words_original_article <= parm_max_percent:\n",
    "        sum_current_word += len(df_article_internal['sentence'][s])\n",
    "    else:\n",
    "#         stop, return index number\n",
    "        cut_index = s - 1\n",
    "        sum_current_word -= len(df_article_internal['sentence'][s-1])\n",
    "\n",
    "#         print('To break')\n",
    "        break\n",
    "\n",
    "# print('End loop')\n",
    "sum_current_percent = sum_current_word / total_words_original_article\n",
    "print('---------- cut by parm_max_percent :')\n",
    "print('sum_current_word  / total_words_original_article:', sum_current_percent)\n",
    "print('cut_index : ', cut_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cut by parm_max_word\n",
    "\n",
    "# Loop Dataframe, accumulate length of sentences, stop when parm_max_word reached, return the index(), cut dataframe to display\n",
    "\n",
    "sum_current_word = 0\n",
    "cut_index = len(df_article_internal['sentence'])\n",
    "\n",
    "# print('Start loop...')\n",
    "for s in range(0, len(df_article_internal['sentence'])):\n",
    "#     print('s : %d' % s)\n",
    "    if sum_current_word <= parm_max_word:\n",
    "        sum_current_word += len(df_article_internal['sentence'][s])\n",
    "    else:\n",
    "#         stop, return index number\n",
    "        cut_index = s - 1\n",
    "        sum_current_word -= len(df_article_internal['sentence'][s-1])\n",
    "#         print('To break')\n",
    "        break\n",
    "\n",
    "# print('End loop')\n",
    "print('---------- cut by parm_max_word :')\n",
    "print('sum_current_word :', sum_current_word)\n",
    "print('cut_index : ', cut_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cut by parm_max_sentence\n",
    "\n",
    "cut_index = parm_max_sentence\n",
    "\n",
    "print('---------- cut by parm_max_sentence :')\n",
    "print('cut_index : ', cut_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract top number of sentences as summary, based on: cut_index\n",
    "df_article_final = df_article_internal[0:cut_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sort by original sentence order \n",
    "df_article_final = df_article_final.sort_values(by=['sentence_id'], ascending=[True])\n",
    "df_article_final[['sentence_id', 'sentence', 'score', 'class_rank', 'paragraph_id', 'sentence_id_paragraph']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# total_words_original_article = df_article['sentence'].map(len).sum()\n",
    "# total_words_internal_article = df_article_internal['sentence'].map(len).sum()\n",
    "total_words_article_summary  = df_article_final['sentence'].map(len).sum()\n",
    "\n",
    "print('total_words_original_article : ', total_words_original_article)\n",
    "print('total_words_internal_article : ', total_words_internal_article)\n",
    "print('total_words_article_summary  : ', total_words_article_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output results to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print('\\n'.join(list(df_article_final['sentence'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with io.open('output_topic_summary.txt','w',encoding='utf8') as f:\n",
    "#     f.write(\"Original Length : %s\" % total_words_original_article)\n",
    "    f.write(\"No. Paragraphs  : %d\" % df_article_internal['paragraph_id'].max())\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Original Length : %s\" % total_words_internal_article)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Summary  Length : %s\" % total_words_article_summary)\n",
    "    f.write(\"\\n\")\n",
    "#     f.write(\"Summary  Ratio  : %s %%\" % (100 * (sum_current_word / total_words_original_article)))\n",
    "    f.write(\"Summary  Ratio  : %.2f %%\" % (100 * (total_words_article_summary / total_words_internal_article)))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Title of Article: %s\" % title)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write('\\n'.join(list(df_article_final['sentence'])))\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This is to check if there is sentence with very few valid/real word, should have very low score.\n",
    "df_article[['sentence', 'word_count', 'sentence_tokenized', 'tfidf', 'score']][df_article['sentence_tokenized'].map(len) <= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
