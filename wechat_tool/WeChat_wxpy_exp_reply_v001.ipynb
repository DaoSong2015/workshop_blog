{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WeChat Tool - Experiment with wxpy Library\n",
    "### www.KudosData.com\n",
    "#### By: Sam GU Zhan\n",
    "#### March, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding=UTF-8\n",
    "from __future__ import division\n",
    "import re\n",
    "\n",
    "# Python2 unicode & float-division support:\n",
    "# from __future__ import unicode_literals, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "\n",
    "# 中文字符和语言处理库\n",
    "import jieba\n",
    "\n",
    "# 机器学习库 sklearn 分类学习模型库\n",
    "#from sklearn import linear_model\n",
    "from sklearn.feature_extraction import DictVectorizer # 数据结构变换：把 Dict 转换为 稀疏矩阵\n",
    "# from sklearn.linear_model import LogisticRegression  # 逻辑回归分类模型\n",
    "# from sklearn.pipeline import make_pipeline # 封装机器学习模型流程\n",
    "# from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "# 中文显示设置\n",
    "from pylab import *  \n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei'] # 指定默认字体  \n",
    "mpl.rcParams['axes.unicode_minus'] = False # 解决保存图像是负号'-'显示为方块的问题 \n",
    "mpl.rcParams['font.size'] = 14 # 设置字体大小\n",
    "\n",
    "np.random.seed(88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from wxpy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python3\n",
    "# 中文分词功能小函数， 输出 字符串， 各词组由空格分隔\n",
    "def KudosData_word_tokenizer(foo):\n",
    "    # remove lead & tail spaces firstly:\n",
    "    foo = foo.strip()\n",
    "    seg_token = jieba.cut(str(foo), cut_all=True)\n",
    "    seg_str = str(' '.join(seg_token)).strip()\n",
    "\n",
    "    return seg_str\n",
    "# Python2\n",
    "# 中文分词功能小函数， 输出 字符串， 各词组由空格分隔\n",
    "# def KudosData_word_tokenizer(foo):\n",
    "#     seg_token = jieba.cut(foo, cut_all=True)\n",
    "#     seg_str = ' '.join(seg_token)\n",
    "#     return seg_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python3\n",
    "# 中文分词功能小函数， 输出 字符串， 各词组由空格分隔\n",
    "def KudosData_word_count(foo):\n",
    "    # remove lead & tail spaces firstly:\n",
    "    foo = foo.strip()\n",
    "    seg_token = jieba.cut(str(foo), cut_all=True)\n",
    "    seg_str = str(' '.join(seg_token)).strip()\n",
    "    seg_count = pd.value_counts(str(seg_str).lower().split(' '))\n",
    "    seg_count = seg_count.to_dict() \n",
    "    seg_count.pop('', None) # remove EMPTY dict key: ''\n",
    "#     输出 dictionary： { key 词组， value 计数 }\n",
    "    #     return seg_count.to_dict()\n",
    "    return seg_count\n",
    "\n",
    "# Python2\n",
    "# 中文分词功能小函数， 输出 dictionary： { key 词组， value 计数 }\n",
    "# def KudosData_word_count(foo):\n",
    "#     seg_token = jieba.cut(foo, cut_all=True)\n",
    "#     seg_str = '^'.join(seg_token)\n",
    "#     seg_count = pd.value_counts(seg_str.lower().split('^'))\n",
    "#     return seg_count.to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process Unicode text input\n",
    "with io.open('input_text.txt','r',encoding='utf8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "title = '''\n",
    "<Dummy Title>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_sentence(text):\n",
    "#     sentence = re.sub(r'\\W+', '#', sentence)\n",
    "    text = re.sub(r'\\t+', '', text) # remove one or more Tab\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linebreak_conversion_win_linux(text):\n",
    "    text = re.sub(r'\\r', '', text) # remove one or more Windows-line-break\n",
    "    text = re.sub(r'\\u3000', ' ', text) # convert white space: \\u3000    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_some_whitespace_1(text): # Does not remove normal Space\n",
    "#     sentence = re.sub(r'\\W+', '#', sentence)\n",
    "    text = re.sub(r'\\t+', '', text) # remove one or more Tab\n",
    "    text = re.sub(r'\\f+', '', text) # remove one or more special Space\n",
    "    text = re.sub(r'\\v+', '', text) # remove one or more special Space\n",
    "    text = re.sub(r' +', ' ', text) # merge two or more Spaces to 1 Space\n",
    "    \n",
    "    # remove lead & tail spaces:\n",
    "    text =text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_some_whitespace_2(text): # Does not remove normal Space\n",
    "#     sentence = re.sub(r'\\W+', '#', sentence)\n",
    "    text = re.sub(r'\\n+', ' ', text) # Change one or more \\n to a Space, this is to merge sentences within paragraph\n",
    "    text = re.sub(r' +', ' ', text) # merge two or more Spaces to 1 Space\n",
    "    text = re.sub(r'(\\^\\*\\#)( +)(\\#\\*\\^)', '^*##*^', text) # remove one or more Spaces between Paragraph-Tags or Sentence-Tags\n",
    "    \n",
    "    text = re.sub(r'(\\#\\*\\^S\\^\\*\\#)+', '#*^S^*#', text) # merge two or more sentence-Tags -> 1 Sentence-Tag\n",
    "    text = re.sub(r'(\\#\\*\\^P\\^\\*\\#)+', '#*^P^*#', text) # merge two or more Paragraph-Tags -> 1 Paragraph-Tag\n",
    "    \n",
    "    # remove a Sentence-Tag immediately before a Paragraph-Tag\n",
    "    text = re.sub(r'(\\#\\*\\^S\\^\\*\\#)( *)(\\#\\*\\^P\\^\\*\\#)', '#*^P^*#', text) \n",
    "\n",
    "    # remove lead & tail spaces:\n",
    "    text =text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Define Paragraph-Tag =  \n",
    "#   #*^P^*#\n",
    "\n",
    "### Define Sentence-Tag =  \n",
    "#   #*^S^*#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add a special tag to end of each paragraph\n",
    "def tag_paragraph(text):\n",
    "    text = re.sub(r'((\\n ) +)+', '#*^P^*#', text) # Tag paragraph, pattern: \\n + two or more Spaces\n",
    "    text = re.sub(r'((\\n\\t) +)+', '#*^P^*#', text) # Tag paragraph, pattern: \\n + two or more Tabs\n",
    "    text = re.sub(r'(\\n( *)\\n)+', '#*^P^*#', text) # Tag paragraph, pattern: \\n + zero or more Spaces + \\n\n",
    "    text = re.sub(r'(\\#\\*\\^P\\^\\*\\#)+', '#*^P^*#', text) # merge two or more Paragraph-Tags -> 1 Paragraph-Tag\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add a special tag to end of each sentence\n",
    "def tag_sentence(text):\n",
    "    text = re.sub(r'。+', '。#*^S^*#', text) # Tag sentence - Chinese\n",
    "    text = re.sub(r'！+', '！#*^S^*#', text) # Tag sentence - Chinese\n",
    "    text = re.sub(r'\\？+', '？#*^S^*#', text) # Tag sentence - Chinese\n",
    "#     text = re.sub(r'；+', '；#*^S^*#', text) # Tag sentence - Chinese\n",
    "\n",
    "    # 2017 MAR 24\n",
    "    text = re.sub(r'(\\.)( +)', '.#*^S^*#', text) # Tag sentence - English\n",
    "    text = re.sub(r'(!)( +)', '!#*^S^*#', text) # Tag sentence - English\n",
    "    text = re.sub(r'\\?( +)', '?#*^S^*#', text) # Tag sentence - English\n",
    "#     text = re.sub(r'(;)( +)', ';#*^S^*#', text) # Tag sentence - English\n",
    "\n",
    "    text = re.sub(r'\\.\\n', '.#*^S^*#', text) # Tag sentence - English\n",
    "    text = re.sub(r'!\\n', '!#*^S^*#', text) # Tag sentence - English\n",
    "    text = re.sub(r'\\?\\n', '?#*^S^*#', text) # Tag sentence - English\n",
    "#     text = re.sub(r';\\n', ';#*^S^*#', text) # Tag sentence - English\n",
    "    \n",
    "    # remove a Sentence-Tag immediately before an ending quotation\n",
    "    text = re.sub(r'\\#\\*\\^S\\^\\*\\#’', '’#*^S^*#', text) # Chinese ’\n",
    "    text = re.sub(r'\\#\\*\\^S\\^\\*\\#”', '”#*^S^*#', text) # Chinese ”\n",
    "    text = re.sub(r'\\#\\*\\^S\\^\\*\\#\\'', '\\'#*^S^*#', text) # English '\n",
    "    text = re.sub(r'\\#\\*\\^S\\^\\*\\#\"', '\"#*^S^*#', text) # English \"\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start tagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content_format = linebreak_conversion_win_linux(content)\n",
    "# content_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content_format = tag_paragraph(content_format)\n",
    "# content_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(content_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content_format = clean_some_whitespace_1(content_format)\n",
    "# content_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(content_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content_format = tag_sentence(content_format)\n",
    "# content_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(content_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "content_format = clean_some_whitespace_2(content_format)\n",
    "# content_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(content_format))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Transfer tagged text to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split a text into paragraphs\n",
    "def split_article_to_paragraphs(text):\n",
    "#     text = text.replace(\"#*^P^*#\", \"#*^S^*#\") # convert Paragraph-Tag        \n",
    "    return text.split(\"#*^P^*#\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split a paragraph into sentences\n",
    "def split_paragraph_to_sentences(text):\n",
    "#     text = text.replace(\"#*^P^*#\", \"#*^S^*#\") # convert Paragraph-Tag        \n",
    "    return text.split(\"#*^S^*#\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1st loop Paragraphs list, 2nd loop Sentences list\n",
    "# create a few new columns, then write into dataframe, together with original Sentence string\n",
    "\n",
    "# define empty dataframe:\n",
    "df_article = pd.DataFrame(columns=('sentence', \n",
    "                                   'word_count', # sentence word count, including punctuations \n",
    "                                   'sentence_id', # unique sentence s/n within an article\n",
    "                                   'sentence_id_paragraph',  # sentence s/n within a paragraph \n",
    "                                   'paragraph_id', \n",
    "                                   'class_rank', \n",
    "                                   'score_word', # score based on word tf-idf\n",
    "                                   'score_sentence', # score based on intersection of sentence pairs\n",
    "                                   'score_word_norm', # Normalized score\n",
    "                                   'score_sentence_norm', # Normalized score\n",
    "                                   'score',\n",
    "                                  ))\n",
    "df_sentence_id = 0\n",
    "\n",
    "# split_article_to_paragraphs:\n",
    "article_paragraphs = split_article_to_paragraphs(content_format)\n",
    "\n",
    "for i in range(0, len(article_paragraphs)):\n",
    "    # split_paragraph_to_sentences:\n",
    "    article_paragraphs_sentences = split_paragraph_to_sentences(article_paragraphs[i].strip())\n",
    "\n",
    "    for j in range(0, len(article_paragraphs_sentences)):\n",
    "        if article_paragraphs_sentences[j].strip() != '':\n",
    "            df_sentence_id = df_sentence_id + 1\n",
    "            # write to dataframe:\n",
    "            df_article.loc[len(df_article)] = [article_paragraphs_sentences[j].strip(), \n",
    "                                               len(article_paragraphs_sentences[j].strip()), \n",
    "                                               df_sentence_id, \n",
    "                                               j+1, \n",
    "                                               i+1, \n",
    "                                               '', \n",
    "                                               '', \n",
    "                                               '', \n",
    "                                               '', \n",
    "                                               '', \n",
    "                                               '']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assume the 1st sentence as Title of Article\n",
    "\n",
    "title = df_article['sentence'][0]\n",
    "print('Title of Article : ', title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_article['sentence'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    }
   ],
   "source": [
    "from wxpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting uuid of QR code.\n",
      "INFO:itchat:Getting uuid of QR code.\n",
      "Downloading QR code.\n",
      "INFO:itchat:Downloading QR code.\n",
      "Please scan the QR code to log in.\n",
      "INFO:itchat:Please scan the QR code to log in.\n",
      "Please press confirm on your phone.\n",
      "INFO:itchat:Please press confirm on your phone.\n",
      "Loading the contact, this may take a little while.\n",
      "INFO:itchat:Loading the contact, this may take a little while.\n",
      "Login successfully as 白黑\n",
      "INFO:itchat:Login successfully as 白黑\n"
     ]
    }
   ],
   "source": [
    "# 初始化机器人，扫码登陆\n",
    "bot = Bot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Friend: 郝素素>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 搜索好友名称\n",
    "# my_friend = bot.friends().search('hss7777777')[0]\n",
    "my_friend = bot.friends().search('郝素素')[0]\n",
    "# my_friend = bot.friends().search('王嘉祎')[0]\n",
    "# my_friend = bot.friends().search('白黑')[0]\n",
    "\n",
    "my_friend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@bot.register()\n",
    "def just_print(msg):\n",
    "    # 打印消息\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@bot.register([my_friend, Group])\n",
    "# @bot.register([my_friend, Group], None, False)\n",
    "# @bot.register()\n",
    "# @bot.register([Group], TEXT, False)\n",
    "\n",
    "def auto_reply(msg):\n",
    "    # 如果是群聊，但没有被 @，则不回复\n",
    "    if isinstance(msg.chat, Group) and not msg.is_at:\n",
    "        return\n",
    "    else:\n",
    "        # 回复消息内容和类型\n",
    "        return '<自动回复>\\n已收到消息:\\n\\\"{}\\\"\\n消息类型：\\n({})'.format(msg.text, msg.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<MessageConfig: 白黑: just_print (Enabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Enabled, Async)>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wxpy.api.bot:\n",
      "An error occurred in <function auto_reply at 0x00000268B5308510>.\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 345, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 844, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connection.py\", line 326, in connect\n",
      "    ssl_context=context)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\util\\ssl_.py\", line 324, in ssl_wrap_socket\n",
      "    return context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\ssl.py\", line 376, in wrap_socket\n",
      "    _context=self)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\ssl.py\", line 747, in __init__\n",
      "    self.do_handshake()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\ssl.py\", line 983, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\ssl.py\", line 628, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:645)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 423, in send\n",
      "    timeout=timeout\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 630, in urlopen\n",
      "    raise SSLError(e)\n",
      "requests.packages.urllib3.exceptions.SSLError: EOF occurred in violation of protocol (_ssl.c:645)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\wxpy\\api\\bot.py\", line 329, in process\n",
      "    msg.reply(ret)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\wxpy\\utils\\misc.py\", line 39, in wrapped\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\wxpy\\api\\chats\\chat.py\", line 78, in send\n",
      "    return self.bot.core.send(msg=str(content), toUserName=self.user_name, mediaId=media_id)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\messages.py\", line 434, in send\n",
      "    r = self.send_msg(msg, toUserName)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\messages.py\", line 253, in send_msg\n",
      "    r = self.send_raw_msg(1, msg, toUserName)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\messages.py\", line 248, in send_raw_msg\n",
      "    data=json.dumps(data, ensure_ascii=False).encode('utf8'))\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 535, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 488, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 609, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 497, in send\n",
      "    raise SSLError(e, request=request)\n",
      "requests.exceptions.SSLError: EOF occurred in violation of protocol (_ssl.c:645)\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 386, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 382, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 1174, in getresponse\n",
      "    response.begin()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 282, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 251, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 423, in send\n",
      "    timeout=timeout\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 649, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\util\\retry.py\", line 347, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\packages\\six.py\", line 685, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 386, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 382, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 1174, in getresponse\n",
      "    response.begin()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 282, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 251, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "requests.packages.urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\login.py\", line 237, in maintain_loop\n",
      "    msgList, contactList = self.get_msg()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\login.py\", line 302, in get_msg\n",
      "    r = self.s.post(url, data=json.dumps(data), headers=headers)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 535, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 488, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 609, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 473, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))\n",
      "\n",
      "ERROR:itchat:Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 386, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 382, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 1174, in getresponse\n",
      "    response.begin()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 282, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 251, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 423, in send\n",
      "    timeout=timeout\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 649, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\util\\retry.py\", line 347, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\packages\\six.py\", line 685, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 386, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 382, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 1174, in getresponse\n",
      "    response.begin()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 282, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 251, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "requests.packages.urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\login.py\", line 237, in maintain_loop\n",
      "    msgList, contactList = self.get_msg()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\login.py\", line 302, in get_msg\n",
      "    r = self.s.post(url, data=json.dumps(data), headers=headers)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 535, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 488, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 609, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 473, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 386, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 382, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 1174, in getresponse\n",
      "    response.begin()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 282, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 251, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 423, in send\n",
      "    timeout=timeout\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 649, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\util\\retry.py\", line 347, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\packages\\six.py\", line 685, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 386, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 382, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 1174, in getresponse\n",
      "    response.begin()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 282, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 251, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "requests.packages.urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\login.py\", line 237, in maintain_loop\n",
      "    msgList, contactList = self.get_msg()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\login.py\", line 302, in get_msg\n",
      "    r = self.s.post(url, data=json.dumps(data), headers=headers)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 535, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 488, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 609, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 473, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))\n",
      "\n",
      "ERROR:itchat:Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 386, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 382, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 1174, in getresponse\n",
      "    response.begin()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 282, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 251, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client.RemoteDisconnected: Remote end closed connection without response\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 423, in send\n",
      "    timeout=timeout\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 649, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\util\\retry.py\", line 347, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\packages\\six.py\", line 685, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 386, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 2, in raise_from\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 382, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 1174, in getresponse\n",
      "    response.begin()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 282, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\http\\client.py\", line 251, in _read_status\n",
      "    raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "requests.packages.urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\login.py\", line 237, in maintain_loop\n",
      "    msgList, contactList = self.get_msg()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\login.py\", line 302, in get_msg\n",
      "    r = self.s.post(url, data=json.dumps(data), headers=headers)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 535, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 488, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 609, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 473, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))\n",
      "\n",
      "ERROR:wxpy.api.bot:\n",
      "An error occurred in <function auto_reply at 0x00000268B5308510>.\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 345, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 844, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connection.py\", line 326, in connect\n",
      "    ssl_context=context)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\util\\ssl_.py\", line 324, in ssl_wrap_socket\n",
      "    return context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\ssl.py\", line 376, in wrap_socket\n",
      "    _context=self)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\ssl.py\", line 747, in __init__\n",
      "    self.do_handshake()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\ssl.py\", line 983, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\ssl.py\", line 628, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:645)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 423, in send\n",
      "    timeout=timeout\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 630, in urlopen\n",
      "    raise SSLError(e)\n",
      "requests.packages.urllib3.exceptions.SSLError: EOF occurred in violation of protocol (_ssl.c:645)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\wxpy\\api\\bot.py\", line 329, in process\n",
      "    msg.reply(ret)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\wxpy\\utils\\misc.py\", line 39, in wrapped\n",
      "    ret = func(*args, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\wxpy\\api\\chats\\chat.py\", line 78, in send\n",
      "    return self.bot.core.send(msg=str(content), toUserName=self.user_name, mediaId=media_id)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\messages.py\", line 434, in send\n",
      "    r = self.send_msg(msg, toUserName)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\messages.py\", line 253, in send_msg\n",
      "    r = self.send_raw_msg(1, msg, toUserName)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\messages.py\", line 248, in send_raw_msg\n",
      "    data=json.dumps(data, ensure_ascii=False).encode('utf8'))\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 535, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 488, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 609, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 497, in send\n",
      "    raise SSLError(e, request=request)\n",
      "requests.exceptions.SSLError: EOF occurred in violation of protocol (_ssl.c:645)\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 345, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 844, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connection.py\", line 326, in connect\n",
      "    ssl_context=context)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\util\\ssl_.py\", line 324, in ssl_wrap_socket\n",
      "    return context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\ssl.py\", line 376, in wrap_socket\n",
      "    _context=self)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\ssl.py\", line 747, in __init__\n",
      "    self.do_handshake()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\ssl.py\", line 983, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\ssl.py\", line 628, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:645)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 423, in send\n",
      "    timeout=timeout\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 630, in urlopen\n",
      "    raise SSLError(e)\n",
      "requests.packages.urllib3.exceptions.SSLError: EOF occurred in violation of protocol (_ssl.c:645)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\storage.py\", line 11, in _contact_change\n",
      "    return fn(core, *args, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\contact.py\", line 243, in update_local_uin\n",
      "    update_friend(core, username)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\contact.py\", line 93, in update_friend\n",
      "    friendList = json.loads(self.s.post(url, data=json.dumps(data), headers=headers\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 535, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 488, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 609, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 497, in send\n",
      "    raise SSLError(e, request=request)\n",
      "requests.exceptions.SSLError: EOF occurred in violation of protocol (_ssl.c:645)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\login.py\", line 239, in maintain_loop\n",
      "    msgList = produce_msg(self, msgList)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\messages.py\", line 174, in produce_msg\n",
      "    msg = update_local_uin(core, m)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\storage.py\", line 11, in _contact_change\n",
      "    return fn(core, *args, **kwargs)\n",
      "RuntimeError: release unlocked lock\n",
      "\n",
      "ERROR:itchat:Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 345, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 844, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connection.py\", line 326, in connect\n",
      "    ssl_context=context)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\util\\ssl_.py\", line 324, in ssl_wrap_socket\n",
      "    return context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\ssl.py\", line 376, in wrap_socket\n",
      "    _context=self)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\ssl.py\", line 747, in __init__\n",
      "    self.do_handshake()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\ssl.py\", line 983, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\ssl.py\", line 628, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:645)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 423, in send\n",
      "    timeout=timeout\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 630, in urlopen\n",
      "    raise SSLError(e)\n",
      "requests.packages.urllib3.exceptions.SSLError: EOF occurred in violation of protocol (_ssl.c:645)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\storage.py\", line 11, in _contact_change\n",
      "    return fn(core, *args, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\contact.py\", line 243, in update_local_uin\n",
      "    update_friend(core, username)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\contact.py\", line 93, in update_friend\n",
      "    friendList = json.loads(self.s.post(url, data=json.dumps(data), headers=headers\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 535, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 488, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 609, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 497, in send\n",
      "    raise SSLError(e, request=request)\n",
      "requests.exceptions.SSLError: EOF occurred in violation of protocol (_ssl.c:645)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\login.py\", line 239, in maintain_loop\n",
      "    msgList = produce_msg(self, msgList)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\components\\messages.py\", line 174, in produce_msg\n",
      "    msg = update_local_uin(core, m)\n",
      "  File \"G:\\Tool_PGM\\Anaconda3\\lib\\site-packages\\itchat\\storage.py\", line 11, in _contact_change\n",
      "    return fn(core, *args, **kwargs)\n",
      "RuntimeError: release unlocked lock\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bot.registered.enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bot.registered.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.registered.enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: just_print (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: just_print (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: just_print (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Disabled, Async)>,\n",
       " <MessageConfig: 白黑: just_print (Enabled, Async)>,\n",
       " <MessageConfig: 白黑: auto_reply (Enabled, Async)>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 堵塞线程，并进入 Python 命令行\n",
    "# embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# my_friend.send('<程序自动发送>\\n<第%d条，共%d条>\\n%s' % (1, len(df_article['sentence']), df_article['sentence'][100]))\n",
    "# my_friend.send('<程序自动发送>\\n恭喜恭喜！\\n红包拿来~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 发送文本给好友\n",
    "count = len(df_article['sentence'])\n",
    "# count = 5\n",
    "for i in range(729, count):\n",
    "    try:\n",
    "        my_friend.send('<第%d条，共%d条>\\n%s' % (i+1, count, df_article['sentence'][i]))\n",
    "        print ('success rec_id = %d' % (i+1))\n",
    "        time.sleep(np.random.randint(low = 5, high = 20))\n",
    "    except:\n",
    "        tmp_rand_int = np.random.randint(low = 70, high = 130)\n",
    "        print ('retry   rec_id = %d, after %d seconds... ' % (i+1, tmp_rand_int))\n",
    "        time.sleep(tmp_rand_int)\n",
    "        try:\n",
    "            my_friend.send('<第%d条，共%d条>\\n%s' % (i+1, count, df_article['sentence'][i]))\n",
    "            print ('success rec_id = %d' % (i+1))\n",
    "            time.sleep(np.random.randint(low = 5, high = 20))\n",
    "        except:\n",
    "            tmp_rand_int = np.random.randint(low = 70, high = 130)\n",
    "            print ('retry   rec_id = %d, after %d seconds... ' % (i+1, tmp_rand_int))\n",
    "            time.sleep(tmp_rand_int)\n",
    "            my_friend.send('<第%d条，共%d条>\\n%s' % (i+1, count, df_article['sentence'][i]))\n",
    "            print ('success rec_id = %d' % (i+1))\n",
    "            time.sleep(np.random.randint(low = 5, high = 20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    try:\n",
    "        my_friend.send('<第%d条，共%d条>\\n%s' % (i+1, count, df_article['sentence'][i]))\n",
    "        print ('success rec_id = %d' % (i+1))\n",
    "        time.sleep(np.random.randint(low = 5, high = 20))\n",
    "    except:\n",
    "        tmp_rand_int = np.random.randint(low = 70, high = 130)\n",
    "        print ('retry   rec_id = %d, after %d seconds... ' % (i+1, tmp_rand_int))\n",
    "        time.sleep(tmp_rand_int)\n",
    "        my_friend.send('<第%d条，共%d条>\\n%s' % (i+1, count, df_article['sentence'][i]))\n",
    "        print ('success rec_id = %d' % (i+1))\n",
    "        time.sleep(np.random.randint(low = 5, high = 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 发送文本给好友\n",
    "count = len(df_article['sentence'])\n",
    "# count = 10\n",
    "for i in range(0, count):\n",
    "    my_friend.send('<第%d条，共%d条>\\n%s' % (i+1, count, df_article['sentence'][i]))\n",
    "    print (i+1)\n",
    "#     my_friend.send('<程序自动发送> \\n恭喜恭喜！\\n红包拿来~')\n",
    "    time.sleep(np.random.randint(low = 10, high = 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# KudosData_word_tokenizer\n",
    "df_article['sentence_tokenized'] = df_article['sentence'].apply(lambda x: KudosData_word_tokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make sure no empty sentences:\n",
    "print('Number of empty sentences in dataframe: %d ' % len(df_article[df_article['sentence_tokenized'] == '']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove invalid empty sentences\n",
    "print(len(df_article))\n",
    "df_article=df_article[df_article['sentence_tokenized'] != '']\n",
    "df_article = df_article.sort_values(by=['sentence_id'],).reset_index(drop=True)\n",
    "print(len(df_article))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KudosData_word_count\n",
    "df_article['sentence_tf'] = df_article['sentence'].apply(lambda x: KudosData_word_count(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = df_article['sentence_tokenized']\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# my_stopword_list = ['and','to','the','of', 'in']\n",
    "#vectorizer = TfidfVectorizer(stop_words=my_stopword_list)\n",
    "\n",
    "# choice of no nomalization of tfidf output (not recommended)\n",
    "#vectorizer = TfidfVectorizer(norm=None)\n",
    "\n",
    "# TF-IDF score\n",
    "tfidf = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# IDF score\n",
    "idf_dict = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "\n",
    "# TF is in df_article[['sentence_tf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 把TF-iDF数值赋予相对应的词组\n",
    "tfidf = tfidf.tocsr()\n",
    "\n",
    "n_docs = tfidf.shape[0]\n",
    "tfidftables = [{} for _ in range(n_docs)]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i, j in zip(*tfidf.nonzero()):\n",
    "    tfidftables[i][terms[j]] = tfidf[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Document-Term-Matrix's TF-IDF matrix size:\n",
    "print ('This tfidf matrix is a very large table: [ %d rows/docs X %d columns/words ]' \n",
    "       % (tfidf.shape[0], tfidf.shape[1]))\n",
    "print ('It contains %d eliments: one score per word per document !'\n",
    "       % (tfidf.shape[0] * tfidf.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add tfidf score into dataframe \n",
    "df_article['tfidf'] = tfidftables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df_article[['sentence', 'sentence_tokenized', 'sentence_tf', 'tfidf']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate importance score for each sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring (1)\n",
    "### Calculate score_word for each sentence, based on sentence word_count tf-idf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# experiment: use tf-idf and len(sentence_tokenized) to calculate score\n",
    "# tmp_mean = tmp_sum / len(df_article['sentence_tokenized'][i])\n",
    "\n",
    "for i in range(0,len(df_article)):\n",
    "    if len(df_article['tfidf'][i]) == 0:\n",
    "        df_article['score_word'][i] = 0\n",
    "    else:\n",
    "        tmp_sum = 0\n",
    "        for key, values in df_article['tfidf'][i].items():\n",
    "            tmp_sum += values\n",
    "        \n",
    "        tmp_mean = tmp_sum / len(df_article['sentence_tokenized'][i])\n",
    "        df_article['score_word'][i] = tmp_mean \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring (2)\n",
    "### Calculate score_sentence for each sentence, based on pair-wise sentence comparison/intersection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Caculate raw intersection score between pair of two sentences, from df_article['sentence_tokenized']\n",
    "def sentences_intersection(sent1tokenized, sent2tokenized):\n",
    "    # www.KudosData.com - Chinese\n",
    "    # split the sentence into words/tokens\n",
    "    s1 = set(sent1tokenized.split(\" \"))\n",
    "    s2 = set(sent2tokenized.split(\" \"))\n",
    "\n",
    "    # If there is not intersection, just return 0\n",
    "    if (len(s1) + len(s2)) == 0:\n",
    "        print('# If there is not intersection, just return 0')\n",
    "        return 0\n",
    "\n",
    "    # Normalize the result by the average number of words\n",
    "    return len(s1.intersection(s2)) / ((len(s1) + len(s2)) / 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below step runs long time... Tuning needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate important score of every pair of sentences\n",
    "\n",
    "n = len(df_article['sentence_tokenized'])\n",
    "        \n",
    "# [Sam python 2.7 -> 3.4] values = [[0 for x in xrange(n)] for x in xrange(n)]\n",
    "df_score_raw_values = [[0 for x in range(n)] for x in range(n)]\n",
    "for i in range(0, n):\n",
    "    for j in range(0, n):\n",
    "        df_score_raw_values[i][j] = sentences_intersection(df_article['sentence_tokenized'][i], \n",
    "                                                           df_article['sentence_tokenized'][j])\n",
    "\n",
    "# The score of a sentence is the sum of all its intersection\n",
    "sentences_dic = {}\n",
    "\n",
    "for i in range(0, n):\n",
    "    df_score = 0\n",
    "    for j in range(0, n):\n",
    "        if i == j:\n",
    "            continue\n",
    "        df_score += df_score_raw_values[i][j]\n",
    "    df_article['score_sentence'][i] = df_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Data (Internal use,  not for production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 图表显示：\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.title(u'图')  \n",
    "plt.xlabel(u'X坐标：Sentence word_count')  \n",
    "plt.ylabel(u'Y坐标：Sentence frequency')  \n",
    "# df_article['word_count'].value_counts().sort_values(ascending=False).plot(kind='bar', color='green')\n",
    "df_article['word_count'].hist(bins=100)\n",
    "# plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 图表显示：\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.title(u'图')  \n",
    "plt.xlabel(u'X坐标：Paragraph_id')  \n",
    "plt.ylabel(u'Y坐标：Sentence frequency')  \n",
    "df_article['paragraph_id'].hist(bins=100)\n",
    "# plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 图表显示：\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.title(u'图')  \n",
    "plt.xlabel(u'X坐标：sentence_id_paragraph')  \n",
    "plt.ylabel(u'Y坐标：Sentence frequency')  \n",
    "df_article['sentence_id_paragraph'].hist(bins=100)\n",
    "# plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 图表显示：\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.title(u'图')  \n",
    "plt.xlabel(u'X坐标：score_word')  \n",
    "plt.ylabel(u'Y坐标：frequency')  \n",
    "df_article['score_word'].hist(bins = 100)\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "#plt.xlim(0,0.5)\n",
    "#plt.ylim(0,0.5)\n",
    "# plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 图表显示：\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.title(u'图')  \n",
    "plt.xlabel(u'X坐标：score_sentence')  \n",
    "plt.ylabel(u'Y坐标：frequency')  \n",
    "df_article['score_sentence'].hist(bins = 100)\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "#plt.xlim(0,0.5)\n",
    "#plt.ylim(0,0.5)\n",
    "# plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_article[(df_article['score_word'] > 0.15) & (df_article['score_word'] < 0.25)]\n",
    "# df_article[(df_article['score_word'] > 0.2)].sort_values(by=['score_sentence', 'score_word'], ascending=[False, False,])\n",
    "# df_article[(df_article['score_sentence'] > 250)].sort_values(by=['score_word', 'score_sentence'], ascending=[False, False,])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# log(score_word)\n",
    "df_article['score_word_log'] = np.log(df_article['score_word'].astype('float64') + \n",
    "                                      df_article[df_article['score_word'] >0 ]['score_word'].min()/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize score_word_log - Zero mean, unit variance\n",
    "\n",
    "# df_article['score_word_norm'] = (df_article['score_word'] - df_article['score_word'].mean()) / df_article['score_word'].std()\n",
    "df_article['score_word_norm'] = (df_article['score_word_log'] - df_article['score_word_log'].mean()) / df_article['score_word_log'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_article['score_word_norm'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize score_sentence - Zero mean, unit variance\n",
    "\n",
    "df_article['score_sentence_norm'] = (df_article['score_sentence'] - df_article['score_sentence'].mean()) / df_article['score_sentence'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_article['score_sentence_norm'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate class_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Score integration\n",
    "# df_article['score'] = (df_article['score_sentence_norm'] + df_article['score_word_norm']) / 2\n",
    "\n",
    "# Sam Gu: 23 Mar 2017 - Experiment found that the score_word, which is based on tf-idf, doesn't seem to work well.\n",
    "#                       score_word     tends to favor short sentences\n",
    "#                       score_sentence tends to favor long  sentences\n",
    "#                       Hence, here we use score_sentence only for final scoring.\n",
    "\n",
    "# df_article['score'] = (df_article['score_word'] + df_article['score_sentence'] ) / 2\n",
    "df_article['score'] = df_article['score_sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Min-Max normalization:\n",
    "df_article['score'] = (df_article['score'] - df_article['score'].min()) / (df_article['score'].max() -df_article['score'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_article['score'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sort firstly\n",
    "df_article = df_article.sort_values(by=['paragraph_id', 'score'], ascending=[True, False]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below step runs long time... Tuning needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate Class_Rank\n",
    "\n",
    "current_class_rank = 0\n",
    "current_paragraph_id = 0\n",
    "\n",
    "for i in range(0, len(df_article)):\n",
    "    if df_article['paragraph_id'][i] != current_paragraph_id: # change of Paragraph, thus reset class_rank\n",
    "        current_class_rank = 1\n",
    "        current_paragraph_id = df_article['paragraph_id'][i]\n",
    "    else:\n",
    "        current_class_rank = current_class_rank + 1\n",
    "        \n",
    "    df_article['class_rank'][i] = current_class_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sort Dataframe to 'result lookup mode'\n",
    "df_article = df_article.sort_values(by=['class_rank', 'score', 'paragraph_id', 'sentence_id'], \n",
    "                                    ascending=[True, False, True, True]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_article[['sentence',\n",
    "           'paragraph_id',\n",
    "           'sentence_id_paragraph',\n",
    "           'class_rank',\n",
    "           'score',\n",
    "           'sentence_tokenized'\n",
    "          ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df_article[(df_article['score'] == 0) | (df_article['score'] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract results based on user parameters:\n",
    "* Max number of words\n",
    "* % of original number of words\n",
    "* Max lines of sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a dataframe copy\n",
    "# Currently, the two dataframes are exactly the same.\n",
    "df_article_internal = pd.DataFrame.copy(df_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_words_original_article = df_article['sentence'].map(len).sum()\n",
    "total_words_internal_article = df_article_internal['sentence'].map(len).sum()\n",
    "# total_words_article_summary  = df_article_final['sentence'].map(len).sum()\n",
    "\n",
    "# print('total_words_original_article : ', total_words_original_article)\n",
    "# print('total_words_internal_article : ', total_words_internal_article)\n",
    "# print('total_words_article_summary  : ', total_words_article_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sam Gu: experiment shows no major improvement to use code in this block:\n",
    "\n",
    "'''\n",
    "\n",
    "# Heuristic cleaning:\n",
    "# 1.Remove sentences, which has only one valid word. \n",
    "# 2.Remove paragraph, which has only single sentence.\n",
    "\n",
    "# 1.\n",
    "df_article_internal = df_article_internal[df_article_internal['sentence_tokenized'].map(len) > 1]\n",
    "print('*** www.KudosData.com *** Removed number of sentences, which has only one valid word : %d'\n",
    "      % (len(df_article) - len(df_article_internal)))\n",
    "\n",
    "# 2.\n",
    "df_article_internal_paragraph = df_article_internal['paragraph_id'].value_counts().to_frame(name = 'sentence_count')\n",
    "df_article_internal_paragraph = df_article_internal_paragraph[df_article_internal_paragraph['sentence_count'] > 1]\n",
    "valid_paragraph_id = df_article_internal_paragraph.index.tolist()\n",
    "df_article_internal = df_article_internal[df_article_internal['paragraph_id'].isin(valid_paragraph_id)] \n",
    "print('*** www.KudosData.com *** Removed number of sentences in total : %d' % (len(df_article) - len(df_article_internal)))\n",
    "\n",
    "# sort Dataframe to 'result lookup mode'\n",
    "df_article_internal = df_article_internal.sort_values(by=['class_rank', 'score', 'paragraph_id', 'sentence_id'], \n",
    "                                    ascending=[True, False, True, True]).reset_index(drop=True)\n",
    "# Above sort a must sort !!! for below processing:\n",
    "# Loop Dataframe, accumulate length of sentences, stop when parm_max_word reached, return the index(), cut dataframe to display\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Accept user parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# valid range: >= 0\n",
    "parm_max_word = 200\n",
    "\n",
    "# valid range: >= 0\n",
    "parm_max_sentence = 10\n",
    "\n",
    "# valid range: [0, 100%]\n",
    "parm_max_percent = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Validation of user parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (isinstance(parm_max_word, int) | isinstance(parm_max_word, float)):\n",
    "    if parm_max_word >= 0:\n",
    "        print('!1! valid input parm_max_word : ', parm_max_word)\n",
    "    else:\n",
    "        print('!2! Invalid input parm_max_word : ', parm_max_word)    \n",
    "else:\n",
    "    print('!3! Invalid input parm_max_word : ', parm_max_word)\n",
    "\n",
    "if (isinstance(parm_max_sentence, int) | isinstance(parm_max_sentence, float)):\n",
    "    if parm_max_sentence >= 0:\n",
    "        print('!1! valid input parm_max_sentence : ', parm_max_sentence)\n",
    "    else:\n",
    "        print('!2! Invalid input parm_max_sentence : ', parm_max_sentence)    \n",
    "else:\n",
    "    print('!3! Invalid input parm_max_sentence : ', parm_max_sentence)\n",
    "\n",
    "if (isinstance(parm_max_percent, int) | isinstance(parm_max_percent, float)):\n",
    "    if parm_max_percent >= 0:\n",
    "        print('!1! valid input parm_max_percent : ', parm_max_percent)\n",
    "    else:\n",
    "        print('!2! Invalid input parm_max_percent : ', parm_max_percent)    \n",
    "else:\n",
    "    print('!3! Invalid input parm_max_percent : ', parm_max_percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cut by parm_max_percent\n",
    "\n",
    "# Loop Dataframe, accumulate length of sentences, stop when parm_max_word reached, return the index(), cut dataframe to display\n",
    "\n",
    "sum_current_word = 0\n",
    "cut_index = len(df_article_internal['sentence'])\n",
    "\n",
    "# print('Start loop...')\n",
    "for s in range(0, len(df_article_internal['sentence'])):\n",
    "#     print('s : %d' % s)\n",
    "    if sum_current_word / total_words_original_article <= parm_max_percent:\n",
    "        sum_current_word += len(df_article_internal['sentence'][s])\n",
    "    else:\n",
    "#         stop, return index number\n",
    "        cut_index = s - 1\n",
    "        sum_current_word -= len(df_article_internal['sentence'][s-1])\n",
    "\n",
    "#         print('To break')\n",
    "        break\n",
    "\n",
    "# print('End loop')\n",
    "sum_current_percent = sum_current_word / total_words_original_article\n",
    "print('---------- cut by parm_max_percent :')\n",
    "print('sum_current_word  / total_words_original_article:', sum_current_percent)\n",
    "print('cut_index : ', cut_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cut by parm_max_word\n",
    "\n",
    "# Loop Dataframe, accumulate length of sentences, stop when parm_max_word reached, return the index(), cut dataframe to display\n",
    "\n",
    "sum_current_word = 0\n",
    "cut_index = len(df_article_internal['sentence'])\n",
    "\n",
    "# print('Start loop...')\n",
    "for s in range(0, len(df_article_internal['sentence'])):\n",
    "#     print('s : %d' % s)\n",
    "    if sum_current_word <= parm_max_word:\n",
    "        sum_current_word += len(df_article_internal['sentence'][s])\n",
    "    else:\n",
    "#         stop, return index number\n",
    "        cut_index = s - 1\n",
    "        sum_current_word -= len(df_article_internal['sentence'][s-1])\n",
    "#         print('To break')\n",
    "        break\n",
    "\n",
    "# print('End loop')\n",
    "print('---------- cut by parm_max_word :')\n",
    "print('sum_current_word :', sum_current_word)\n",
    "print('cut_index : ', cut_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cut by parm_max_sentence\n",
    "\n",
    "cut_index = parm_max_sentence\n",
    "\n",
    "print('---------- cut by parm_max_sentence :')\n",
    "print('cut_index : ', cut_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract top number of sentences as summary, based on: cut_index\n",
    "df_article_final = df_article_internal[0:cut_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sort by original sentence order \n",
    "df_article_final = df_article_final.sort_values(by=['sentence_id'], ascending=[True])\n",
    "df_article_final[['sentence_id', 'sentence', 'score', 'class_rank', 'paragraph_id', 'sentence_id_paragraph']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# total_words_original_article = df_article['sentence'].map(len).sum()\n",
    "# total_words_internal_article = df_article_internal['sentence'].map(len).sum()\n",
    "total_words_article_summary  = df_article_final['sentence'].map(len).sum()\n",
    "\n",
    "print('total_words_original_article : ', total_words_original_article)\n",
    "print('total_words_internal_article : ', total_words_internal_article)\n",
    "print('total_words_article_summary  : ', total_words_article_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output results to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print('\\n'.join(list(df_article_final['sentence'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with io.open('output_topic_summary.txt','w',encoding='utf8') as f:\n",
    "#     f.write(\"Original Length : %s\" % total_words_original_article)\n",
    "    f.write(\"No. Paragraphs  : %d\" % df_article_internal['paragraph_id'].max())\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Original Length : %s\" % total_words_internal_article)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Summary  Length : %s\" % total_words_article_summary)\n",
    "    f.write(\"\\n\")\n",
    "#     f.write(\"Summary  Ratio  : %s %%\" % (100 * (sum_current_word / total_words_original_article)))\n",
    "    f.write(\"Summary  Ratio  : %.2f %%\" % (100 * (total_words_article_summary / total_words_internal_article)))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Title of Article: %s\" % title)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write('\\n'.join(list(df_article_final['sentence'])))\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This is to check if there is sentence with very few valid/real word, should have very low score.\n",
    "df_article[['sentence', 'word_count', 'sentence_tokenized', 'tfidf', 'score']][df_article['sentence_tokenized'].map(len) <= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
