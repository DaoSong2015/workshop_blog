{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何使用和开发微信聊天机器人的系列教程\n",
    "# A workshop to develop & use an intelligent and interactive chat-bot in WeChat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WeChat is a popular social media app, which has more than 800 million monthly active users.\n",
    "\n",
    "<img src='http://www.kudosdata.com/wp-content/uploads/2016/11/cropped-KudosLogo1.png' width=30% style=\"float: right;\">\n",
    "<img src='reference/WeChat_SamGu_QR.png' width=10% style=\"float: right;\">\n",
    "\n",
    "### http://www.KudosData.com\n",
    "\n",
    "by: Sam.Gu@KudosData.com\n",
    "\n",
    "\n",
    "May 2017 ========== Scan the QR code to become trainer's friend in WeChat ========>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第三课：自然语言处理\n",
    "### Lesson 3: Natural Language Processing\n",
    "* 消息文字转成语音 (Speech synthesis: text to voice)\n",
    "* 语音转换成消息文字 (Speech recognition: voice to text)\n",
    "* 消息文字的多语言互译 (Text based language translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Using Google Cloud Platform's Machine Learning APIs\n",
    "\n",
    "First, visit <a href=\"http://console.cloud.google.com/apis\">API console</a>, choose \"Credentials\" on the left-hand menu.  Choose \"Create Credentials\" and generate an API key for your application. You should probably restrict it by IP address to prevent abuse, but for now, just  leave that field blank and delete the API key after trying out this demo.\n",
    "\n",
    "Copy-paste your API Key here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here I read in my own API_KEY from a file, which is not shared in Github repository:\n",
    "with io.open('../../API_KEY.txt') as fp: \n",
    "    for line in fp: APIKEY = line\n",
    "\n",
    "# You need to un-comment below line and replace 'APIKEY' variable with your own GCP API key:\n",
    "# APIKEY=\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the same API console, choose \"Dashboard\" on the left-hand menu and \"Enable API\".\n",
    "\n",
    "Enable the following APIs for your project (search for them) if they are not already enabled:\n",
    "<ol>\n",
    "<li> Google Translate API </li>\n",
    "<li> Google Cloud Vision API </li>\n",
    "<li> Google Natural Language API </li>\n",
    "<li> Google Cloud Speech API </li>\n",
    "</ol>\n",
    "\n",
    "Finally, because we are calling the APIs from Python (clients in many other languages are available), let's install the Python package (it's not installed by default on Datalab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2016 Google Inc.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"); \n",
    "\n",
    "!pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入需要用到的一些功能程序库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "█\r"
     ]
    }
   ],
   "source": [
    "import time, datetime, requests, itchat\n",
    "from itchat.content import *\n",
    "from googleapiclient.discovery import build\n",
    "# Below is for GCP Language Tranlation API\n",
    "service = build('translate', 'v2', developerKey=APIKEY)\n",
    "# Below is for GCP Speech API\n",
    "# sservice = build('speech', 'v1beta1', developerKey=APIKEY)\n",
    "speech_service = build('speech', 'v1', developerKey=APIKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图片二进制base64码转换 (Define image pre-processing functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the base64 encoding library.\n",
    "import base64\n",
    "# Pass the image data to an encoding function.\n",
    "def encode_image(image_file):\n",
    "    with io.open(image_file, \"rb\") as image_file:\n",
    "        image_content = image_file.read()\n",
    "    return base64.b64encode(image_content)\n",
    "\n",
    "# Pass the image data to an encoding function.\n",
    "def encode_audio(audio_file):\n",
    "    with io.open(audio_file, 'rb') as audio_file:\n",
    "        audio_content = audio_file.read()\n",
    "    return base64.b64encode(audio_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器智能API接口控制参数 (Define control parameters for API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# control parameter for Image API:\n",
    "parm_image_maxResults = 10 # max objects or faces to be extracted from image analysis\n",
    "\n",
    "# control parameter for Language Translation API:\n",
    "parm_translation_origin_language = '' # original language in text: to be overwriten by TEXT_DETECTION\n",
    "parm_translation_target_language = 'zh' # target language for translation: Chinese\n",
    "\n",
    "# control parameter for Language Translation API:\n",
    "parm_speech_origin_language = 'en-US' # speech API 'voice to text' language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### * 消息文字转成语音 (Speech synthesis: text to voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "# 'LABEL_DETECTION'\n",
    "def KudosData_LABEL_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    image_analysis_reply = u'\\n[ ' + API_type + u' 物体识别 ]\\n'\n",
    "    # 'LABEL_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        for i in range(len(responses['responses'][0]['labelAnnotations'])):\n",
    "            image_analysis_reply += str(responses['responses'][0]['labelAnnotations'][i]['description']) \\\n",
    "            + '\\n( score ' +  str(responses['responses'][0]['labelAnnotations'][i]['score']) + ' )\\n'\n",
    "    return image_analysis_reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### * 语音转换成消息文字 (Speech recognition: voice to text)\n",
    "\n",
    "The Speech API can work on streaming data, audio content encoded and embedded directly into the POST message, or on a file on Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_file_path = 'reference/voice.mono.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# response = speech_service.speech().syncrecognize(\n",
    "response = speech_service.speech().recognize(\n",
    "    body={\n",
    "        'config': {\n",
    "#             'encoding': 'LINEAR16',\n",
    "#             'sampleRateHertz': 16000,\n",
    "            'languageCode': parm_speech_origin_language\n",
    "        },\n",
    "        'audio': {\n",
    "            'content': encode_audio(audio_file_path)\n",
    "            }\n",
    "        }).execute()\n",
    "print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if response != {}:\n",
    "    for i in range(len(response['results'])):\n",
    "        print response['results'][i]['alternatives'][0]['transcript']\n",
    "        print '( confidence: %f )' % response['results'][i]['alternatives'][0]['confidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_file_path = 'reference/audio.mp3.flac' # mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'results': [{u'alternatives': [{u'confidence': 0.36370814, u'transcript': u'Rapunzel movie'}]}, {u'alternatives': [{u'confidence': 0.61125255, u'transcript': u' automatron to the street'}]}]}\n"
     ]
    }
   ],
   "source": [
    "# response = speech_service.speech().syncrecognize(\n",
    "response = speech_service.speech().recognize(\n",
    "    body={\n",
    "        'config': {\n",
    "#             'encoding': 'LINEAR16',\n",
    "#             'sampleRateHertz': 16000,\n",
    "            'languageCode': parm_speech_origin_language\n",
    "        },\n",
    "        'audio': {\n",
    "            'content': encode_audio(audio_file_path)\n",
    "            }\n",
    "        }).execute()\n",
    "print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapunzel movie\n",
      "( confidence: 0.363708 )\n",
      " automatron to the street\n",
      "( confidence: 0.611253 )\n"
     ]
    }
   ],
   "source": [
    "if response != {}:\n",
    "    for i in range(len(response['results'])):\n",
    "        print response['results'][i]['alternatives'][0]['transcript']\n",
    "        print '( confidence: %f )' % response['results'][i]['alternatives'][0]['confidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/notebooks/workshop_blog/wechat_tool_testing\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 3.1.7 Copyright (c) 2000-2017 the FFmpeg developers\n",
      "  built with gcc 6.3.1 (GCC) 20161221 (Red Hat 6.3.1-1)\n",
      "  configuration: --prefix=/usr --bindir=/usr/bin --datadir=/usr/share/ffmpeg --incdir=/usr/include/ffmpeg --libdir=/usr/lib64 --mandir=/usr/share/man --arch=x86_64 --optflags='-O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune=generic' --extra-ldflags='-Wl,-z,relro -specs=/usr/lib/rpm/redhat/redhat-hardened-ld' --enable-bzlib --disable-crystalhd --enable-fontconfig --enable-frei0r --enable-gcrypt --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libcdio --enable-indev=jack --enable-libfreetype --enable-libfribidi --enable-libgsm --enable-libmp3lame --enable-nvenc --extra-cflags=-I/usr/include/nvenc --enable-openal --enable-opencl --enable-libopencv --enable-opengl --enable-libopenjpeg --enable-libopus --enable-libpulse --enable-libschroedinger --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libvorbis --enable-libv4l2 --enable-libvpx --enable-libx264 --enable-libx265 --enable-libxvid --enable-x11grab --enable-avfilter --enable-avresample --enable-postproc --enable-pthreads --disable-static --enable-shared --enable-gpl --disable-debug --disable-stripping --shlibdir=/usr/lib64 --enable-libmfx --enable-runtime-cpudetect\n",
      "  libavutil      55. 28.100 / 55. 28.100\n",
      "  libavcodec     57. 48.101 / 57. 48.101\n",
      "  libavformat    57. 41.100 / 57. 41.100\n",
      "  libavdevice    57.  0.101 / 57.  0.101\n",
      "  libavfilter     6. 47.100 /  6. 47.100\n",
      "  libavresample   3.  0.  0 /  3.  0.  0\n",
      "  libswscale      4.  1.100 /  4.  1.100\n",
      "  libswresample   2.  1.100 /  2.  1.100\n",
      "  libpostproc    54.  0.100 / 54.  0.100\n",
      "\u001b[0;35m[mp3 @ 0x565138663c00] \u001b[0m\u001b[0;33mEstimating duration from bitrate, this may be inaccurate\n",
      "\u001b[0mInput #0, mp3, from 'reference/eng_sample.mp3':\n",
      "  Metadata:\n",
      "    Engineer        : Mitsue Sound Creative\n",
      "    date            : 2006\n",
      "  Duration: 00:00:18.06, start: 0.000000, bitrate: 128 kb/s\n",
      "    Stream #0:0: Audio: mp3, 44100 Hz, mono, s16p, 128 kb/s\n",
      "\u001b[1;35m[flac @ 0x565138674740] \u001b[0m\u001b[0;33mUsing AVStream.codec to pass codec parameters to muxers is deprecated, use AVStream.codecpar instead.\n",
      "\u001b[0mOutput #0, flac, to 'reference/eng_sample.mp3.flac':\n",
      "  Metadata:\n",
      "    Engineer        : Mitsue Sound Creative\n",
      "    date            : 2006\n",
      "    encoder         : Lavf57.41.100\n",
      "    Stream #0:0: Audio: flac, 44100 Hz, mono, s16, 128 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc57.48.101 flac\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mp3 (native) -> flac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "size=     718kB time=00:00:18.05 bitrate= 325.7kbits/s speed=57.4x    \n",
      "video:0kB audio:709kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.147343%\n"
     ]
    }
   ],
   "source": [
    "!rm -rf reference/eng_sample.mp3.flac\n",
    "!ffmpeg -i reference/eng_sample.mp3 -ac 1 reference/eng_sample.mp3.flac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_file_path = 'reference/eng_sample.mp3.flac' # mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'results': [{u'alternatives': [{u'confidence': 0.8938378, u'transcript': u'in central Japan a spider weeds or web in a field of growing rice rice has been apart of Japan for so long that has a shape the land indeed it has become so much a part of the Japanese landscape it is created a unique environment is Central to both the people who created it and the wild animals and not share it'}]}]}\n"
     ]
    }
   ],
   "source": [
    "# response = speech_service.speech().syncrecognize(\n",
    "response = speech_service.speech().recognize(\n",
    "    body={\n",
    "        'config': {\n",
    "#             'encoding': 'LINEAR16',\n",
    "#             'sampleRateHertz': 16000,\n",
    "            'languageCode': parm_speech_origin_language\n",
    "        },\n",
    "        'audio': {\n",
    "            'content': encode_audio(audio_file_path)\n",
    "            }\n",
    "        }).execute()\n",
    "print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in central Japan a spider weeds or web in a field of growing rice rice has been apart of Japan for so long that has a shape the land indeed it has become so much a part of the Japanese landscape it is created a unique environment is Central to both the people who created it and the wild animals and not share it\n",
      "( confidence: 0.893838 )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if response != {}:\n",
    "    for i in range(len(response['results'])):\n",
    "        print response['results'][i]['alternatives'][0]['transcript']\n",
    "        print '( confidence: %f )\\n' % response['results'][i]['alternatives'][0]['confidence']        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 3.1.7 Copyright (c) 2000-2017 the FFmpeg developers\n",
      "  built with gcc 6.3.1 (GCC) 20161221 (Red Hat 6.3.1-1)\n",
      "  configuration: --prefix=/usr --bindir=/usr/bin --datadir=/usr/share/ffmpeg --incdir=/usr/include/ffmpeg --libdir=/usr/lib64 --mandir=/usr/share/man --arch=x86_64 --optflags='-O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune=generic' --extra-ldflags='-Wl,-z,relro -specs=/usr/lib/rpm/redhat/redhat-hardened-ld' --enable-bzlib --disable-crystalhd --enable-fontconfig --enable-frei0r --enable-gcrypt --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libcdio --enable-indev=jack --enable-libfreetype --enable-libfribidi --enable-libgsm --enable-libmp3lame --enable-nvenc --extra-cflags=-I/usr/include/nvenc --enable-openal --enable-opencl --enable-libopencv --enable-opengl --enable-libopenjpeg --enable-libopus --enable-libpulse --enable-libschroedinger --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libvorbis --enable-libv4l2 --enable-libvpx --enable-libx264 --enable-libx265 --enable-libxvid --enable-x11grab --enable-avfilter --enable-avresample --enable-postproc --enable-pthreads --disable-static --enable-shared --enable-gpl --disable-debug --disable-stripping --shlibdir=/usr/lib64 --enable-libmfx --enable-runtime-cpudetect\n",
      "  libavutil      55. 28.100 / 55. 28.100\n",
      "  libavcodec     57. 48.101 / 57. 48.101\n",
      "  libavformat    57. 41.100 / 57. 41.100\n",
      "  libavdevice    57.  0.101 / 57.  0.101\n",
      "  libavfilter     6. 47.100 /  6. 47.100\n",
      "  libavresample   3.  0.  0 /  3.  0.  0\n",
      "  libswscale      4.  1.100 /  4.  1.100\n",
      "  libswresample   2.  1.100 /  2.  1.100\n",
      "  libpostproc    54.  0.100 / 54.  0.100\n",
      "\u001b[0;35m[mp3 @ 0x55e4a088ec00] \u001b[0m\u001b[0;33mEstimating duration from bitrate, this may be inaccurate\n",
      "\u001b[0mInput #0, mp3, from 'reference/eng_sample.mp3':\n",
      "  Metadata:\n",
      "    Engineer        : Mitsue Sound Creative\n",
      "    date            : 2006\n",
      "  Duration: 00:00:18.06, start: 0.000000, bitrate: 128 kb/s\n",
      "    Stream #0:0: Audio: mp3, 44100 Hz, mono, s16p, 128 kb/s\n",
      "\u001b[1;35m[wav @ 0x55e4a089f740] \u001b[0m\u001b[0;33mUsing AVStream.codec to pass codec parameters to muxers is deprecated, use AVStream.codecpar instead.\n",
      "\u001b[0mOutput #0, wav, to 'reference/eng_sample.mp3.wav':\n",
      "  Metadata:\n",
      "    Engineer        : Mitsue Sound Creative\n",
      "    ICRD            : 2006\n",
      "    ISFT            : Lavf57.41.100\n",
      "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, mono, s16, 705 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc57.48.101 pcm_s16le\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mp3 (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "size=    1555kB time=00:00:18.05 bitrate= 705.6kbits/s speed=  75x    \n",
      "video:0kB audio:1555kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.005779%\n"
     ]
    }
   ],
   "source": [
    "!rm -rf reference/eng_sample.mp3.wav\n",
    "!ffmpeg -i reference/eng_sample.mp3 -ac 1 reference/eng_sample.mp3.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_file_path = 'reference/eng_sample.mp3.wav' # mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'results': [{u'alternatives': [{u'confidence': 0.9217215, u'transcript': u'in central Japan a spider weaves a web in a field of growing rice rice has been apart of Japan for so long that has a shape the land indeed it has become so much a part of the Japanese landscape it is created a unique environment is Central to both the people who created it and the wild animals in their share it'}]}]}\n"
     ]
    }
   ],
   "source": [
    "# response = speech_service.speech().syncrecognize(\n",
    "response = speech_service.speech().recognize(\n",
    "    body={\n",
    "        'config': {\n",
    "#             'encoding': 'LINEAR16',\n",
    "#             'sampleRateHertz': 16000,\n",
    "            'languageCode': parm_speech_origin_language\n",
    "        },\n",
    "        'audio': {\n",
    "            'content': encode_audio(audio_file_path)\n",
    "            }\n",
    "        }).execute()\n",
    "print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in central Japan a spider weaves a web in a field of growing rice rice has been apart of Japan for so long that has a shape the land indeed it has become so much a part of the Japanese landscape it is created a unique environment is Central to both the people who created it and the wild animals in their share it\n",
      "( confidence: 0.921721 )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if response != {}:\n",
    "    for i in range(len(response['results'])):\n",
    "        print response['results'][i]['alternatives'][0]['transcript']\n",
    "        print '( confidence: %f )\\n' % response['results'][i]['alternatives'][0]['confidence']        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_file_path = 'reference/audio.raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'results': [{u'alternatives': [{u'confidence': 0.98267895, u'transcript': u'how old is the Brooklyn Bridge'}]}]}\n"
     ]
    }
   ],
   "source": [
    "# response = speech_service.speech().syncrecognize(\n",
    "response = speech_service.speech().recognize(\n",
    "    body={\n",
    "        'config': {\n",
    "            'encoding': 'LINEAR16',\n",
    "            'sampleRateHertz': 16000,\n",
    "            'languageCode': parm_speech_origin_language\n",
    "        },\n",
    "        'audio': {\n",
    "            'content': encode_audio(audio_file_path)\n",
    "            }\n",
    "        }).execute()\n",
    "print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how old is the Brooklyn Bridge\n",
      "( confidence: 0.982679 )\n"
     ]
    }
   ],
   "source": [
    "if response != {}:\n",
    "    print response['results'][0]['alternatives'][0]['transcript']\n",
    "    print '( confidence: %f )' % response['results'][0]['alternatives'][0]['confidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<open file 'reference/voicewav.mp3', mode 'wb+' at 0x7fa1bc099d20>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AudioSegment.from_file(\"reference/voice.wav\").export(\"reference/voicewav.mp3\", format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wav_audio = AudioSegment.from_file(\"reference/voice.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sound = AudioSegment.from_mp3(\"reference/audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wav_audio = AudioSegment.from_file(\"voice.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wav_audio = AudioSegment.from_file(audio_file_path, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import requests\n",
    "import shutil\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!which sox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "audio = requests.get('http://somesite.com/some.mp3')\n",
    "sox = shutil.which('sox') or glob.glob('C:\\Program Files*\\sox*\\sox.exe')[0]\n",
    "p = subprocess.Popen(sox + ' -t mp3 - -t flac - rate 16k', stdin = subprocess.PIPE, stdout = subprocess.PIPE, shell = True)\n",
    "stdout, stderr = p.communicate(audio.content)\n",
    "url = 'http://www.google.com/speech-api/v2/recognize?client=chromium&lang=en-US&key=AIzaSyBOti4mM-6x9WDnZIjIeyEU21OpBXqWBgw'\n",
    "headers = {'Content-Type': 'audio/x-flac; rate=16000'}\n",
    "response = requests.post(url, data = stdout, headers = headers).text\n",
    "\n",
    "result = None\n",
    "for line in response.split('\\n'):\n",
    "    try:\n",
    "        result = json.loads(line)['result'][0]['alternative'][0]['transcript']\n",
    "        break\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Running Speech API\n",
    "\n",
    "def KudosData_voice_to_text(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    image_analysis_reply = u'\\n[ ' + API_type + u' 地标识别 ]\\n'\n",
    "    # 'LANDMARK_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        for i in range(len(responses['responses'][0]['landmarkAnnotations'])):\n",
    "            image_analysis_reply += str(responses['responses'][0]['landmarkAnnotations'][i]['description']) \\\n",
    "            + '\\n( score ' +  str(responses['responses'][0]['landmarkAnnotations'][i]['score']) + ' )\\n'\n",
    "    return image_analysis_reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### * 消息文字的多语言互译 (Text based language translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "# 'TEXT_DETECTION'\n",
    "def KudosData_TEXT_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    image_analysis_reply = u'\\n[ ' + API_type + u' 文字提取 ]\\n'\n",
    "    # 'TEXT_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        image_analysis_reply += u'----- Start Origin Text -----\\n'\n",
    "        image_analysis_reply += u'( Original Language 原文: ' + str(responses['responses'][0]['textAnnotations'][0]['locale']) \\\n",
    "        + ' )\\n'        \n",
    "        image_analysis_reply += responses['responses'][0]['textAnnotations'][0]['description'] + '----- End Origin Text -----\\n'\n",
    "\n",
    "        ##############################################################################################################\n",
    "        #                                        translation of detected text                                        #\n",
    "        ##############################################################################################################\n",
    "        parm_translation_origin_language = str(responses['responses'][0]['textAnnotations'][0]['locale'])\n",
    "        # Call translation if parm_translation_origin_language is not parm_translation_target_language\n",
    "        if parm_translation_origin_language != parm_translation_target_language:\n",
    "            inputs=[responses['responses'][0]['textAnnotations'][0]['description']] # TEXT_DETECTION OCR results only\n",
    "            outputs = service.translations().list(source=parm_translation_origin_language, \n",
    "                                                  target=parm_translation_target_language, q=inputs).execute()\n",
    "            image_analysis_reply += u'\\n----- Start Translation -----\\n'\n",
    "            image_analysis_reply += u'( Target Language 译文: ' + parm_translation_target_language + ' )\\n'\n",
    "            image_analysis_reply += outputs['translations'][0]['translatedText'] + '\\n' + '----- End Translation -----\\n'\n",
    "            print('Compeleted: Translation    API ...')\n",
    "        ##############################################################################################################\n",
    "        \n",
    "    return image_analysis_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用微信App扫QR码图片来自动登录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itchat.auto_login(hotReload=True) # hotReload=True: 退出程序后暂存登陆状态。即使程序关闭，一定时间内重新开启也可以不用重新扫码。\n",
    "# itchat.auto_login(enableCmdQR=-2) # enableCmdQR=-2: 命令行显示QR图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@itchat.msg_register([PICTURE])\n",
    "# @itchat.msg_register([PICTURE], isGroupChat=True)\n",
    "def download_files(msg):\n",
    "    parm_translation_origin_language = 'zh' # will be overwriten by TEXT_DETECTION\n",
    "    msg.download(msg.fileName)\n",
    "    print('\\nDownloaded image file name is: %s' % msg['FileName'])\n",
    "    image_base64 = encode_image(msg['FileName'])\n",
    "    \n",
    "    ##############################################################################################################\n",
    "    #                                          call image analysis APIs                                          #\n",
    "    ##############################################################################################################\n",
    "    \n",
    "    image_analysis_reply = u'[ Image Analysis Results 图像识别结果 ]\\n'\n",
    "\n",
    "    # 1. LABEL_DETECTION:\n",
    "    image_analysis_reply += KudosData_LABEL_DETECTION(image_base64, 'LABEL_DETECTION', parm_image_maxResults)\n",
    "    # 2. LANDMARK_DETECTION:\n",
    "    image_analysis_reply += KudosData_LANDMARK_DETECTION(image_base64, 'LANDMARK_DETECTION', parm_image_maxResults)\n",
    "    # 3. LOGO_DETECTION:\n",
    "    image_analysis_reply += KudosData_LOGO_DETECTION(image_base64, 'LOGO_DETECTION', parm_image_maxResults)\n",
    "    # 4. TEXT_DETECTION:\n",
    "    image_analysis_reply += KudosData_TEXT_DETECTION(image_base64, 'TEXT_DETECTION', parm_image_maxResults)\n",
    "    # 5. FACE_DETECTION:\n",
    "    image_analysis_reply += KudosData_FACE_DETECTION(image_base64, 'FACE_DETECTION', parm_image_maxResults)\n",
    "    # 6. SAFE_SEARCH_DETECTION:\n",
    "    image_analysis_reply += KudosData_SAFE_SEARCH_DETECTION(image_base64, 'SAFE_SEARCH_DETECTION', parm_image_maxResults)\n",
    "\n",
    "    print('Compeleted: Image Analysis API ...')\n",
    "    \n",
    "    return image_analysis_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "itchat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# interupt kernel, then logout\n",
    "itchat.logout() # 安全退出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 恭喜您！已经完成了：\n",
    "### 第三课：自然语言处理\n",
    "### Lesson 3: Natural Language Processing\n",
    "* 消息文字转成语音 (Speech synthesis: text to voice)\n",
    "* 语音转换成消息文字 (Speech recognition: voice to text)\n",
    "* 消息文字的多语言互译 (Text based language translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下一课是:\n",
    "### 第三课：自然语言处理\n",
    "### Lesson 3: Natural Language Processing\n",
    "* 消息文字转成语音 (Speech synthesis: text to voice)\n",
    "* 语音转换成消息文字 (Speech recognition: voice to text)\n",
    "* 消息文字的多语言互译 (Text based language translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://www.kudosdata.com/wp-content/uploads/2016/11/cropped-KudosLogo1.png' width=30% style=\"float: right;\">\n",
    "<img src='reference/WeChat_SamGu_QR.png' width=10% style=\"float: left;\">\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
