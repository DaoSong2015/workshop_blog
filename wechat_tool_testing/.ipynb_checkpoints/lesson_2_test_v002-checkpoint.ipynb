{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Using Machine Learning APIs </h1>\n",
    "\n",
    "First, visit <a href=\"http://console.cloud.google.com/apis\">API console</a>, choose \"Credentials\" on the left-hand menu.  Choose \"Create Credentials\" and generate an API key for your application. You should probably restrict it by IP address to prevent abuse, but for now, just  leave that field blank and delete the API key after trying out this demo.\n",
    "\n",
    "Copy-paste your API Key here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here I read in my own API_KEY from a file, which is not shared in Github repository:\n",
    "with open('../../API_KEY.txt') as fp: \n",
    "  for line in fp: \n",
    "    APIKEY = line\n",
    "    \n",
    "# You need to un-comment below line and replace 'APIKEY' variable with your own GCP API key:\n",
    "# APIKEY=\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note: Make sure you generate an API Key and replace the value above. The sample key will not work.</b>\n",
    "\n",
    "From the same API console, choose \"Dashboard\" on the left-hand menu and \"Enable API\".\n",
    "\n",
    "Enable the following APIs for your project (search for them) if they are not already enabled:\n",
    "<ol>\n",
    "<li> Google Translate API </li>\n",
    "<li> Google Cloud Vision API </li>\n",
    "<li> Google Natural Language API </li>\n",
    "<li> Google Cloud Speech API </li>\n",
    "</ol>\n",
    "\n",
    "Finally, because we are calling the APIs from Python (clients in many other languages are available), let's install the Python package (it's not installed by default on Datalab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: google-api-python-client in /home/user/env/lib/python2.7/site-packages\n",
      "Requirement already up-to-date: six<2dev,>=1.6.1 in /usr/lib/python2.7/site-packages (from google-api-python-client)\n",
      "Requirement already up-to-date: oauth2client<5.0.0dev,>=1.5.0 in /home/user/env/lib/python2.7/site-packages (from google-api-python-client)\n",
      "Requirement already up-to-date: uritemplate<4dev,>=3.0.0 in /home/user/env/lib/python2.7/site-packages (from google-api-python-client)\n",
      "Requirement already up-to-date: httplib2<1dev,>=0.9.2 in /home/user/env/lib/python2.7/site-packages (from google-api-python-client)\n",
      "Requirement already up-to-date: rsa>=3.1.4 in /usr/lib/python2.7/site-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client)\n",
      "Requirement already up-to-date: pyasn1>=0.1.7 in /home/user/env/lib/python2.7/site-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client)\n",
      "Requirement already up-to-date: pyasn1-modules>=0.0.5 in /usr/lib/python2.7/site-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client)\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2016 Google Inc.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "!pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017-05-02 Sam: API experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the base64 encoding library.\n",
    "import base64\n",
    "\n",
    "# Pass the image data to an encoding function.\n",
    "def encode_image(image):\n",
    "  with open(image, \"rb\") as image_file:\n",
    "    image_content = image_file.read()\n",
    "#   image_content = image.read()\n",
    "  return base64.b64encode(image_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API: LABEL_DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "\n",
    "# IMAGE=\"gs://cloud-training-demos/vision/sign2.jpg\"\n",
    "IMAGE_FILE = 'image/normal_valve_39.jpg'\n",
    "\n",
    "vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": encode_image(IMAGE_FILE)\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': 'LABEL_DETECTION',\n",
    "                    'maxResults': 5,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "responses = request.execute(num_retries=3)\n",
    "# print responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'labelAnnotations': [{u'description': u'machine',\n",
       "   u'mid': u'/m/0dkw5',\n",
       "   u'score': 0.8280869},\n",
       "  {u'description': u'vehicle', u'mid': u'/m/07yv9', u'score': 0.8117244},\n",
       "  {u'description': u'product', u'mid': u'/m/01jwgf', u'score': 0.769973},\n",
       "  {u'description': u'aircraft engine',\n",
       "   u'mid': u'/m/014yck',\n",
       "   u'score': 0.57185394},\n",
       "  {u'description': u'robot', u'mid': u'/m/06fgw', u'score': 0.5057605}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses['responses'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'machine', 0.82808685)\n",
      "(u'vehicle', 0.8117244)\n",
      "(u'product', 0.7699737)\n",
      "(u'aircraft engine', 0.57185394)\n",
      "(u'robot', 0.5057603)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(responses['responses'][0]['labelAnnotations'])):\n",
    "  print(responses['responses'][0]['labelAnnotations'][i]['description'], responses['responses'][0]['labelAnnotations'][i]['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API: TEXT_DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "\n",
    "# IMAGE=\"gs://cloud-training-demos/vision/sign2.jpg\"\n",
    "IMAGE_FILE = 'image/sc002.jpg'\n",
    "\n",
    "vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": encode_image(IMAGE_FILE)\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': 'TEXT_DETECTION',\n",
    "                    'maxResults': 3,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "responses = request.execute(num_retries=3)\n",
    "# print responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "responses['responses'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en \n",
      "\n",
      "co Interactive, Iterative Dew X\n",
      "O CPB 100\n",
      "x Quickstart l Google C\n",
      "x\n",
      "C Secure\n",
      "I https://www.coursera.org\n",
      "fundamentals,lecture/lfB\n",
      "/learn/gop-big-data\n",
      "CO Ursera\n",
      "Compute Engine\n",
      "cpb10 x\n",
      "koy cpb100\n",
      "K- C Secure\n",
      "I /compute/ir\n",
      "Back to Week 1\n",
      "E Google Cloud Platform\n",
      "8. cpb 100\n",
      "Data and Machine L\n",
      "on Google Cloud Pl\n",
      "aGE Compute En\n",
      "Specialization\n",
      "A Google Cloud Datalab\n",
      "X\n",
      "c R Secure I https://8081-dot-23\n",
      "VM instances\n",
      "About GCP Big Data Instance groups\n",
      "Machine Learning\n",
      "A Google Cloud Datalab\n",
      "Fundamentals\n",
      "Instance templa\n",
      "Disks\n",
      "Notebook\n",
      "Folder\n",
      "1 Upload\n",
      "Meet Your Instruct\n",
      "Snapshots\n",
      "datalab\n",
      "docs\n",
      "Welcome to Introd\n",
      "H mages\n",
      "\n"
     ]
    }
   ],
   "source": [
    "foreigntext = responses['responses'][0]['textAnnotations'][0]['description']\n",
    "foreignlang = responses['responses'][0]['textAnnotations'][0]['locale']\n",
    "print foreignlang, '\\n\\n', foreigntext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API: FACE_DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "\n",
    "# IMAGE=\"gs://cloud-training-demos/vision/sign2.jpg\"\n",
    "IMAGE_FILE = 'image/ZhanGu.png'\n",
    "\n",
    "vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": encode_image(IMAGE_FILE)\n",
    "                },\n",
    "                'features': [\n",
    "                    {\n",
    "                    'type': 'FACE_DETECTION',\n",
    "                    'maxResults': 5,\n",
    "                    }\n",
    "                ]\n",
    "            }],\n",
    "        })\n",
    "responses = request.execute(num_retries=3)\n",
    "# print responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'faceAnnotations': [{u'angerLikelihood': u'VERY_UNLIKELY',\n",
       "   u'blurredLikelihood': u'VERY_UNLIKELY',\n",
       "   u'boundingPoly': {u'vertices': [{u'x': 53, u'y': 108},\n",
       "     {u'x': 174, u'y': 108},\n",
       "     {u'x': 174, u'y': 249},\n",
       "     {u'x': 53, u'y': 249}]},\n",
       "   u'detectionConfidence': 0.7664121,\n",
       "   u'fdBoundingPoly': {u'vertices': [{u'x': 67, u'y': 154},\n",
       "     {u'x': 159, u'y': 154},\n",
       "     {u'x': 159, u'y': 246},\n",
       "     {u'x': 67, u'y': 246}]},\n",
       "   u'headwearLikelihood': u'VERY_UNLIKELY',\n",
       "   u'joyLikelihood': u'VERY_LIKELY',\n",
       "   u'landmarkingConfidence': 0.41711053,\n",
       "   u'landmarks': [{u'position': {u'x': 98.2182,\n",
       "      u'y': 182.45367,\n",
       "      u'z': -0.00019850906},\n",
       "     u'type': u'LEFT_EYE'},\n",
       "    {u'position': {u'x': 133.16412, u'y': 183.55904, u'z': 0.5359883},\n",
       "     u'type': u'RIGHT_EYE'},\n",
       "    {u'position': {u'x': 85.20849, u'y': 171.92538, u'z': 0.2908663},\n",
       "     u'type': u'LEFT_OF_LEFT_EYEBROW'},\n",
       "    {u'position': {u'x': 107.199, u'y': 176.24681, u'z': -9.448704},\n",
       "     u'type': u'RIGHT_OF_LEFT_EYEBROW'},\n",
       "    {u'position': {u'x': 124.78933, u'y': 177.57271, u'z': -9.005842},\n",
       "     u'type': u'LEFT_OF_RIGHT_EYEBROW'},\n",
       "    {u'position': {u'x': 146.45602, u'y': 175.74516, u'z': 1.5379243},\n",
       "     u'type': u'RIGHT_OF_RIGHT_EYEBROW'},\n",
       "    {u'position': {u'x': 115.323975, u'y': 184.25525, u'z': -7.4069333},\n",
       "     u'type': u'MIDPOINT_BETWEEN_EYES'},\n",
       "    {u'position': {u'x': 114.188156, u'y': 207.92479, u'z': -11.156328},\n",
       "     u'type': u'NOSE_TIP'},\n",
       "    {u'position': {u'x': 113.079315, u'y': 217.35155, u'z': 0.96011835},\n",
       "     u'type': u'UPPER_LIP'},\n",
       "    {u'position': {u'x': 112.81494, u'y': 229.63928, u'z': 7.6728883},\n",
       "     u'type': u'LOWER_LIP'},\n",
       "    {u'position': {u'x': 96.03583, u'y': 217.76898, u'z': 12.300608},\n",
       "     u'type': u'MOUTH_LEFT'},\n",
       "    {u'position': {u'x': 129.93706, u'y': 219.23291, u'z': 12.862124},\n",
       "     u'type': u'MOUTH_RIGHT'},\n",
       "    {u'position': {u'x': 112.8809, u'y': 222.7081, u'z': 5.5191383},\n",
       "     u'type': u'MOUTH_CENTER'},\n",
       "    {u'position': {u'x': 124.161514, u'y': 207.24904, u'z': 3.444908},\n",
       "     u'type': u'NOSE_BOTTOM_RIGHT'},\n",
       "    {u'position': {u'x': 103.94828, u'y': 205.55904, u'z': 2.928921},\n",
       "     u'type': u'NOSE_BOTTOM_LEFT'},\n",
       "    {u'position': {u'x': 113.59065, u'y': 210.92929, u'z': -1.3391147},\n",
       "     u'type': u'NOSE_BOTTOM_CENTER'},\n",
       "    {u'position': {u'x': 97.25396, u'y': 180.56783, u'z': -3.1792524},\n",
       "     u'type': u'LEFT_EYE_TOP_BOUNDARY'},\n",
       "    {u'position': {u'x': 104.394684, u'y': 183.80626, u'z': 0.44604298},\n",
       "     u'type': u'LEFT_EYE_RIGHT_CORNER'},\n",
       "    {u'position': {u'x': 97.43729, u'y': 184.72226, u'z': 0.39329696},\n",
       "     u'type': u'LEFT_EYE_BOTTOM_BOUNDARY'},\n",
       "    {u'position': {u'x': 89.884705, u'y': 181.32492, u'z': 3.0741987},\n",
       "     u'type': u'LEFT_EYE_LEFT_CORNER'},\n",
       "    {u'position': {u'x': 96.49831, u'y': 182.50241, u'z': -0.9507047},\n",
       "     u'type': u'LEFT_EYE_PUPIL'},\n",
       "    {u'position': {u'x': 133.8112, u'y': 182.6511, u'z': -2.426996},\n",
       "     u'type': u'RIGHT_EYE_TOP_BOUNDARY'},\n",
       "    {u'position': {u'x': 140.90996, u'y': 183.82068, u'z': 4.078948},\n",
       "     u'type': u'RIGHT_EYE_RIGHT_CORNER'},\n",
       "    {u'position': {u'x': 133.42679, u'y': 186.49892, u'z': 1.1070598},\n",
       "     u'type': u'RIGHT_EYE_BOTTOM_BOUNDARY'},\n",
       "    {u'position': {u'x': 126.21923, u'y': 184.17899, u'z': 0.7658457},\n",
       "     u'type': u'RIGHT_EYE_LEFT_CORNER'},\n",
       "    {u'position': {u'x': 134.05122, u'y': 184.64546, u'z': -0.2307559},\n",
       "     u'type': u'RIGHT_EYE_PUPIL'},\n",
       "    {u'position': {u'x': 96.32383, u'y': 170.85597, u'z': -8.266499},\n",
       "     u'type': u'LEFT_EYEBROW_UPPER_MIDPOINT'},\n",
       "    {u'position': {u'x': 136.0188, u'y': 173.15668, u'z': -7.44482},\n",
       "     u'type': u'RIGHT_EYEBROW_UPPER_MIDPOINT'},\n",
       "    {u'position': {u'x': 72.64019, u'y': 184.0611, u'z': 48.091625},\n",
       "     u'type': u'LEFT_EAR_TRAGION'},\n",
       "    {u'position': {u'x': 155.73845, u'y': 188.8457, u'z': 49.777115},\n",
       "     u'type': u'RIGHT_EAR_TRAGION'},\n",
       "    {u'position': {u'x': 115.93595, u'y': 177.05246, u'z': -10.672142},\n",
       "     u'type': u'FOREHEAD_GLABELLA'},\n",
       "    {u'position': {u'x': 111.58379, u'y': 243.19308, u'z': 17.42048},\n",
       "     u'type': u'CHIN_GNATHION'},\n",
       "    {u'position': {u'x': 75.247314, u'y': 211.23697, u'z': 41.13703},\n",
       "     u'type': u'CHIN_LEFT_GONION'},\n",
       "    {u'position': {u'x': 150.33948, u'y': 215.52731, u'z': 42.661495},\n",
       "     u'type': u'CHIN_RIGHT_GONION'}],\n",
       "   u'panAngle': 1.2272005,\n",
       "   u'rollAngle': 3.6618297,\n",
       "   u'sorrowLikelihood': u'VERY_UNLIKELY',\n",
       "   u'surpriseLikelihood': u'VERY_UNLIKELY',\n",
       "   u'tiltAngle': -17.743513,\n",
       "   u'underExposedLikelihood': u'VERY_UNLIKELY'}]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses['responses'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face No.1 Detected...\n",
      "     angerLikelihood        : VERY_UNLIKELY\n",
      "     blurredLikelihood      : VERY_UNLIKELY\n",
      "     headwearLikelihood     : VERY_UNLIKELY\n",
      "     joyLikelihood          : VERY_LIKELY\n",
      "     sorrowLikelihood       : VERY_UNLIKELY\n",
      "     surpriseLikelihood     : VERY_UNLIKELY\n",
      "     underExposedLikelihood : VERY_UNLIKELY\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(responses['responses'][0]['faceAnnotations'])):\n",
    "  print('Face No.%d Detected...' % (i+1))\n",
    "  print('     angerLikelihood        : %s' % responses['responses'][0]['faceAnnotations'][i][u'angerLikelihood'])\n",
    "  print('     blurredLikelihood      : %s' % responses['responses'][0]['faceAnnotations'][i][u'blurredLikelihood'])\n",
    "  print('     headwearLikelihood     : %s' % responses['responses'][0]['faceAnnotations'][i][u'headwearLikelihood'])\n",
    "  print('     joyLikelihood          : %s' % responses['responses'][0]['faceAnnotations'][i][u'joyLikelihood'])\n",
    "  print('     sorrowLikelihood       : %s' % responses['responses'][0]['faceAnnotations'][i][u'sorrowLikelihood'])\n",
    "  print('     surpriseLikelihood     : %s' % responses['responses'][0]['faceAnnotations'][i][u'surpriseLikelihood'])\n",
    "  print('     underExposedLikelihood : %s' % responses['responses'][0]['faceAnnotations'][i][u'underExposedLikelihood'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API: LANDMARK_DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "\n",
    "# IMAGE=\"gs://cloud-training-demos/vision/sign2.jpg\"\n",
    "IMAGE_FILE = 'image/new-york-statue-of-liberty.jpg'\n",
    "\n",
    "vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": encode_image(IMAGE_FILE)\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': 'LANDMARK_DETECTION',\n",
    "                    'maxResults': 5,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "responses = request.execute(num_retries=3)\n",
    "# print responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'landmarkAnnotations': [{u'boundingPoly': {u'vertices': [{u'x': 54,\n",
       "      u'y': 34},\n",
       "     {u'x': 359, u'y': 34},\n",
       "     {u'x': 359, u'y': 327},\n",
       "     {u'x': 54, u'y': 327}]},\n",
       "   u'description': u'Statue of Liberty',\n",
       "   u'locations': [{u'latLng': {u'latitude': 40.689261,\n",
       "      u'longitude': -74.044482}}],\n",
       "   u'mid': u'/m/072p8',\n",
       "   u'score': 0.98105204}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses['responses'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'Statue of Liberty', 0.98105204)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(responses['responses'][0]['landmarkAnnotations'])):\n",
    "    print(responses['responses'][0]['landmarkAnnotations'][i]['description'], responses['responses'][0]['landmarkAnnotations'][i]['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API: LOGO_DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "\n",
    "# IMAGE=\"gs://cloud-training-demos/vision/sign2.jpg\"\n",
    "IMAGE_FILE = 'image/sc002.jpg'\n",
    "\n",
    "vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": encode_image(IMAGE_FILE)\n",
    "                },\n",
    "                'features': [{\n",
    "#                     'type': 'TEXT_DETECTION',\n",
    "                    'type': 'LOGO_DETECTION',\n",
    "                    'maxResults': 3,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "responses = request.execute(num_retries=3)\n",
    "# print responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'logoAnnotations': [{u'boundingPoly': {u'vertices': [{u'x': 46, u'y': 93},\n",
       "     {u'x': 142, u'y': 93},\n",
       "     {u'x': 142, u'y': 109},\n",
       "     {u'x': 46, u'y': 109}]},\n",
       "   u'description': u'Open Universities Australia',\n",
       "   u'score': 0.34260604}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses['responses'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Open Universities Australia'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses['responses'][0]['logoAnnotations'][0]['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API: SAFE_SEARCH_DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "\n",
    "# IMAGE=\"gs://cloud-training-demos/vision/sign2.jpg\"\n",
    "# IMAGE_FILE = 'image/Lenna.png'\n",
    "IMAGE_FILE = 'image/adult0.jpg'\n",
    "# IMAGE_FILE = 'image/adult1.jpg'\n",
    "# IMAGE_FILE = 'image/adult2.jpg'\n",
    "\n",
    "vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": encode_image(IMAGE_FILE)\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': 'FACE_DETECTION',\n",
    "                    'maxResults': 5,},\n",
    "                    {\n",
    "                    'type': 'SAFE_SEARCH_DETECTION',\n",
    "                    'maxResults': 5,\n",
    "                    }\n",
    "                ]\n",
    "            }],\n",
    "        })\n",
    "responses = request.execute(num_retries=3)\n",
    "# print responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'faceAnnotations': [{u'angerLikelihood': u'VERY_UNLIKELY',\n",
       "   u'blurredLikelihood': u'VERY_UNLIKELY',\n",
       "   u'boundingPoly': {u'vertices': [{u'x': 196, u'y': 112},\n",
       "     {u'x': 271, u'y': 112},\n",
       "     {u'x': 271, u'y': 200},\n",
       "     {u'x': 196, u'y': 200}]},\n",
       "   u'detectionConfidence': 0.99981904,\n",
       "   u'fdBoundingPoly': {u'vertices': [{u'x': 203, u'y': 133},\n",
       "     {u'x': 258, u'y': 133},\n",
       "     {u'x': 258, u'y': 189},\n",
       "     {u'x': 203, u'y': 189}]},\n",
       "   u'headwearLikelihood': u'VERY_UNLIKELY',\n",
       "   u'joyLikelihood': u'VERY_UNLIKELY',\n",
       "   u'landmarkingConfidence': 0.7658484,\n",
       "   u'landmarks': [{u'position': {u'x': 218.40509,\n",
       "      u'y': 149.86897,\n",
       "      u'z': 0.00012949333},\n",
       "     u'type': u'LEFT_EYE'},\n",
       "    {u'position': {u'x': 240.37619, u'y': 150.26128, u'z': -5.176103},\n",
       "     u'type': u'RIGHT_EYE'},\n",
       "    {u'position': {u'x': 211.37724, u'y': 145.12497, u'z': 4.263804},\n",
       "     u'type': u'LEFT_OF_LEFT_EYEBROW'},\n",
       "    {u'position': {u'x': 223.1314, u'y': 144.95131, u'z': -5.2163424},\n",
       "     u'type': u'RIGHT_OF_LEFT_EYEBROW'},\n",
       "    {u'position': {u'x': 233.6994, u'y': 144.91037, u'z': -7.7600484},\n",
       "     u'type': u'LEFT_OF_RIGHT_EYEBROW'},\n",
       "    {u'position': {u'x': 248.70532, u'y': 145.4612, u'z': -4.4622536},\n",
       "     u'type': u'RIGHT_OF_RIGHT_EYEBROW'},\n",
       "    {u'position': {u'x': 228.20198, u'y': 149.39957, u'z': -7.2100716},\n",
       "     u'type': u'MIDPOINT_BETWEEN_EYES'},\n",
       "    {u'position': {u'x': 226.21738, u'y': 162.60193, u'z': -14.966595},\n",
       "     u'type': u'NOSE_TIP'},\n",
       "    {u'position': {u'x': 227.27403, u'y': 170.4228, u'z': -10.36498},\n",
       "     u'type': u'UPPER_LIP'},\n",
       "    {u'position': {u'x': 227.83057, u'y': 178.44594, u'z': -9.391895},\n",
       "     u'type': u'LOWER_LIP'},\n",
       "    {u'position': {u'x': 221.29247, u'y': 174.8489, u'z': -3.0496745},\n",
       "     u'type': u'MOUTH_LEFT'},\n",
       "    {u'position': {u'x': 237.03258, u'y': 175.28601, u'z': -6.8231273},\n",
       "     u'type': u'MOUTH_RIGHT'},\n",
       "    {u'position': {u'x': 227.67566, u'y': 174.29274, u'z': -8.994094},\n",
       "     u'type': u'MOUTH_CENTER'},\n",
       "    {u'position': {u'x': 233.79004, u'y': 165.07086, u'z': -7.961669},\n",
       "     u'type': u'NOSE_BOTTOM_RIGHT'},\n",
       "    {u'position': {u'x': 222.78183, u'y': 164.85876, u'z': -5.183136},\n",
       "     u'type': u'NOSE_BOTTOM_LEFT'},\n",
       "    {u'position': {u'x': 227.28467, u'y': 166.1348, u'z': -10.052748},\n",
       "     u'type': u'NOSE_BOTTOM_CENTER'},\n",
       "    {u'position': {u'x': 217.94054, u'y': 148.72281, u'z': -1.3441757},\n",
       "     u'type': u'LEFT_EYE_TOP_BOUNDARY'},\n",
       "    {u'position': {u'x': 222.80273, u'y': 150.66255, u'z': -0.97693586},\n",
       "     u'type': u'LEFT_EYE_RIGHT_CORNER'},\n",
       "    {u'position': {u'x': 218.32413, u'y': 151.69963, u'z': -0.31067982},\n",
       "     u'type': u'LEFT_EYE_BOTTOM_BOUNDARY'},\n",
       "    {u'position': {u'x': 214.29396, u'y': 150.65317, u'z': 3.0773823},\n",
       "     u'type': u'LEFT_EYE_LEFT_CORNER'},\n",
       "    {u'position': {u'x': 217.78343, u'y': 150.40775, u'z': -0.40997663},\n",
       "     u'type': u'LEFT_EYE_PUPIL'},\n",
       "    {u'position': {u'x': 240.29025, u'y': 148.92154, u'z': -6.57105},\n",
       "     u'type': u'RIGHT_EYE_TOP_BOUNDARY'},\n",
       "    {u'position': {u'x': 245.50052, u'y': 150.93039, u'z': -4.2159343},\n",
       "     u'type': u'RIGHT_EYE_RIGHT_CORNER'},\n",
       "    {u'position': {u'x': 240.62059, u'y': 152.05118, u'z': -5.5231113},\n",
       "     u'type': u'RIGHT_EYE_BOTTOM_BOUNDARY'},\n",
       "    {u'position': {u'x': 236.0612, u'y': 150.75043, u'z': -4.0913997},\n",
       "     u'type': u'RIGHT_EYE_LEFT_CORNER'},\n",
       "    {u'position': {u'x': 240.70831, u'y': 150.62018, u'z': -5.807219},\n",
       "     u'type': u'RIGHT_EYE_PUPIL'},\n",
       "    {u'position': {u'x': 216.91743, u'y': 142.02283, u'z': -1.6776427},\n",
       "     u'type': u'LEFT_EYEBROW_UPPER_MIDPOINT'},\n",
       "    {u'position': {u'x': 241.1648, u'y': 142.23563, u'z': -7.334281},\n",
       "     u'type': u'RIGHT_EYEBROW_UPPER_MIDPOINT'},\n",
       "    {u'position': {u'x': 210.13501, u'y': 164.1795, u'z': 29.7929},\n",
       "     u'type': u'LEFT_EAR_TRAGION'},\n",
       "    {u'position': {u'x': 260.83768, u'y': 164.67287, u'z': 17.915297},\n",
       "     u'type': u'RIGHT_EAR_TRAGION'},\n",
       "    {u'position': {u'x': 228.3608, u'y': 144.36005, u'z': -7.2865686},\n",
       "     u'type': u'FOREHEAD_GLABELLA'},\n",
       "    {u'position': {u'x': 228.03462, u'y': 189.44398, u'z': -7.0784683},\n",
       "     u'type': u'CHIN_GNATHION'},\n",
       "    {u'position': {u'x': 210.02437, u'y': 177.98312, u'z': 18.853506},\n",
       "     u'type': u'CHIN_LEFT_GONION'},\n",
       "    {u'position': {u'x': 255.73587, u'y': 178.51321, u'z': 8.12907},\n",
       "     u'type': u'CHIN_RIGHT_GONION'}],\n",
       "   u'panAngle': -13.210897,\n",
       "   u'rollAngle': 1.6385092,\n",
       "   u'sorrowLikelihood': u'VERY_UNLIKELY',\n",
       "   u'surpriseLikelihood': u'VERY_UNLIKELY',\n",
       "   u'tiltAngle': 4.8966994,\n",
       "   u'underExposedLikelihood': u'VERY_UNLIKELY'}],\n",
       " u'safeSearchAnnotation': {u'adult': u'UNLIKELY',\n",
       "  u'medical': u'UNLIKELY',\n",
       "  u'spoof': u'VERY_UNLIKELY',\n",
       "  u'violence': u'VERY_UNLIKELY'}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses['responses'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face No.1 Detected...\n",
      "     angerLikelihood        : VERY_UNLIKELY\n",
      "     blurredLikelihood      : VERY_UNLIKELY\n",
      "     headwearLikelihood     : VERY_UNLIKELY\n",
      "     joyLikelihood          : VERY_UNLIKELY\n",
      "     sorrowLikelihood       : VERY_UNLIKELY\n",
      "     surpriseLikelihood     : VERY_UNLIKELY\n",
      "     underExposedLikelihood : VERY_UNLIKELY\n",
      "\n",
      "safeSearchAnnotation : {u'medical': u'UNLIKELY', u'spoof': u'VERY_UNLIKELY', u'violence': u'VERY_UNLIKELY', u'adult': u'UNLIKELY'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(responses['responses'][0]['faceAnnotations'])):\n",
    "  print('Face No.%d Detected...' % (i+1))\n",
    "  print('     angerLikelihood        : %s' % responses['responses'][0]['faceAnnotations'][i][u'angerLikelihood'])\n",
    "  print('     blurredLikelihood      : %s' % responses['responses'][0]['faceAnnotations'][i][u'blurredLikelihood'])\n",
    "  print('     headwearLikelihood     : %s' % responses['responses'][0]['faceAnnotations'][i][u'headwearLikelihood'])\n",
    "  print('     joyLikelihood          : %s' % responses['responses'][0]['faceAnnotations'][i][u'joyLikelihood'])\n",
    "  print('     sorrowLikelihood       : %s' % responses['responses'][0]['faceAnnotations'][i][u'sorrowLikelihood'])\n",
    "  print('     surpriseLikelihood     : %s' % responses['responses'][0]['faceAnnotations'][i][u'surpriseLikelihood'])\n",
    "  print('     underExposedLikelihood : %s' % responses['responses'][0]['faceAnnotations'][i][u'underExposedLikelihood'])\n",
    "\n",
    "print('\\nsafeSearchAnnotation : %s' % responses['responses'][0]['safeSearchAnnotation'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API: IMAGE_PROPERTIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "\n",
    "# IMAGE=\"gs://cloud-training-demos/vision/sign2.jpg\"\n",
    "IMAGE_FILE = 'image/ZhanGu.png'\n",
    "\n",
    "vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": encode_image(IMAGE_FILE)\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': 'IMAGE_PROPERTIES',\n",
    "                    'maxResults': 5,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "responses = request.execute(num_retries=3)\n",
    "# print responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'cropHintsAnnotation': {u'cropHints': [{u'boundingPoly': {u'vertices': [{},\n",
       "      {u'x': 639},\n",
       "      {u'x': 639, u'y': 479},\n",
       "      {u'y': 479}]},\n",
       "    u'confidence': 1,\n",
       "    u'importanceFraction': 0.53}]},\n",
       " u'imagePropertiesAnnotation': {u'dominantColors': {u'colors': [{u'color': {u'blue': 242,\n",
       "      u'green': 241,\n",
       "      u'red': 240},\n",
       "     u'pixelFraction': 0.47353128,\n",
       "     u'score': 0.21038339},\n",
       "    {u'color': {u'blue': 159, u'green': 136, u'red': 23},\n",
       "     u'pixelFraction': 0.0732053,\n",
       "     u'score': 0.13511749},\n",
       "    {u'color': {u'blue': 175, u'green': 162, u'red': 31},\n",
       "     u'pixelFraction': 0.06207923,\n",
       "     u'score': 0.11201539},\n",
       "    {u'color': {u'blue': 75, u'green': 61, u'red': 41},\n",
       "     u'pixelFraction': 0.071646236,\n",
       "     u'score': 0.09705272},\n",
       "    {u'color': {u'blue': 120, u'green': 114, u'red': 106},\n",
       "     u'pixelFraction': 0.012543405,\n",
       "     u'score': 0.009770275},\n",
       "    {u'color': {u'blue': 32, u'green': 45, u'red': 74},\n",
       "     u'pixelFraction': 0.0047480687,\n",
       "     u'score': 0.0059098294},\n",
       "    {u'color': {u'blue': 176, u'green': 133, u'red': 15},\n",
       "     u'pixelFraction': 0.06094536,\n",
       "     u'score': 0.12761103},\n",
       "    {u'color': {u'blue': 184, u'green': 163, u'red': 79},\n",
       "     u'pixelFraction': 0.025937213,\n",
       "     u'score': 0.046901565},\n",
       "    {u'color': {u'blue': 157, u'green': 146, u'red': 22},\n",
       "     u'pixelFraction': 0.020551343,\n",
       "     u'score': 0.035608463},\n",
       "    {u'color': {u'blue': 229, u'green': 211, u'red': 137},\n",
       "     u'pixelFraction': 0.013606407,\n",
       "     u'score': 0.026594225}]}}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses['responses'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Invoke Translate API </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is it really this easy? -> 这真的很容易吗？\n",
      "amazing technology -> 惊人的技术\n",
      "wow -> 哇\n"
     ]
    }
   ],
   "source": [
    "# running Translate API\n",
    "from googleapiclient.discovery import build\n",
    "service = build('translate', 'v2', developerKey=APIKEY)\n",
    "\n",
    "# use the service\n",
    "inputs = ['is it really this easy?', 'amazing technology', 'wow']\n",
    "outputs = service.translations().list(source='en', target='zh', q=inputs).execute()\n",
    "# print outputs\n",
    "for input, output in zip(inputs, outputs['translations']):\n",
    "  print u\"{0} -> {1}\".format(input, output['translatedText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Invoke Vision API </h2>\n",
    "\n",
    "The Vision API can work off an image in Cloud Storage or embedded directly into a POST message. I'll use Cloud Storage and do OCR on this image: <img src=\"https://storage.googleapis.com/cloud-training-demos/vision/sign2.jpg\" width=\"200\" />.  That photograph is from http://www.publicdomainpictures.net/view-image.php?image=15842\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sam: OCR / TEXT_DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Translate sign </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "co Interactive, Iterative Dew X\n",
      "O CPB 100\n",
      "x Quickstart l Google C\n",
      "x\n",
      "C Secure\n",
      "I https://www.coursera.org\n",
      "fundamentals,lecture/lfB\n",
      "/learn/gop-big-data\n",
      "CO Ursera\n",
      "Compute Engine\n",
      "cpb10 x\n",
      "koy cpb100\n",
      "K- C Secure\n",
      "I /compute/ir\n",
      "Back to Week 1\n",
      "E Google Cloud Platform\n",
      "8. cpb 100\n",
      "Data and Machine L\n",
      "on Google Cloud Pl\n",
      "aGE Compute En\n",
      "Specialization\n",
      "A Google Cloud Datalab\n",
      "X\n",
      "c R Secure I https://8081-dot-23\n",
      "VM instances\n",
      "About GCP Big Data Instance groups\n",
      "Machine Learning\n",
      "A Google Cloud Datalab\n",
      "Fundamentals\n",
      "Instance templa\n",
      "Disks\n",
      "Notebook\n",
      "Folder\n",
      "1 Upload\n",
      "Meet Your Instruct\n",
      "Snapshots\n",
      "datalab\n",
      "docs\n",
      "Welcome to Introd\n",
      "H mages\n",
      " -> co互动，Iterative Dew XO CPB 100 x Quickstart l Google C x C Secure I https://www.coursera.org基础知识，讲座/ lfB / learn / gop-big-data CO Ursera Compute Engine cpb10 x koy cpb100 K- C安全I /计算/ ir返回第1周E Google云平台8. cpb 100数据和机器在Google云计算专业化Google Cloud Datalab X c R Secure I https：// 8081-dot-23 VM实例关于GCP大数据实例组机器学习Google Cloud Datalab基础知识实例模板磁盘笔记本文件夹1上传满足您的指导快照datalab docs欢迎来到Introd H的mages\n"
     ]
    }
   ],
   "source": [
    "inputs=[foreigntext]\n",
    "outputs = service.translations().list(source=foreignlang, target='zh', q=inputs).execute()\n",
    "# print outputs\n",
    "for input, output in zip(inputs, outputs['translations']):\n",
    "  print u\"{0} -> {1}\".format(input, output['translatedText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Sentiment analysis with Language API </h2>\n",
    "\n",
    "Let's evaluate the sentiment of some famous quotes using Google Cloud Natural Language API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLARITY=1 MAGNITUDE=0.8 for To succeed, you must have tremendous perseverance, tremendous will.\n",
      "POLARITY=-1 MAGNITUDE=0 for It’s not that I’m so smart, it’s just that I stay with problems longer.\n",
      "POLARITY=1 MAGNITUDE=0.6 for Love is quivering happiness.\n",
      "POLARITY=1 MAGNITUDE=0.8 for Love is of all passions the strongest, for it attacks simultaneously the head, the heart, and the senses.\n",
      "POLARITY=-1 MAGNITUDE=0.1 for What difference does it make to the dead, the orphans and the homeless, whether the mad destruction is wrought under the name of totalitarianism or in the holy name of liberty or democracy?\n",
      "POLARITY=-1 MAGNITUDE=0.4 for When someone you love dies, and you’re not expecting it, you don’t lose her all at once; you lose her in pieces over a long time — the way the mail stops coming, and her scent fades from the pillows and even from the clothes in her closet and drawers. \n"
     ]
    }
   ],
   "source": [
    "lservice = build('language', 'v1beta1', developerKey=APIKEY)\n",
    "quotes = [\n",
    "  'To succeed, you must have tremendous perseverance, tremendous will.',\n",
    "  'It’s not that I’m so smart, it’s just that I stay with problems longer.',\n",
    "  'Love is quivering happiness.',\n",
    "  'Love is of all passions the strongest, for it attacks simultaneously the head, the heart, and the senses.',\n",
    "  'What difference does it make to the dead, the orphans and the homeless, whether the mad destruction is wrought under the name of totalitarianism or in the holy name of liberty or democracy?',\n",
    "  'When someone you love dies, and you’re not expecting it, you don’t lose her all at once; you lose her in pieces over a long time — the way the mail stops coming, and her scent fades from the pillows and even from the clothes in her closet and drawers. '\n",
    "]\n",
    "for quote in quotes:\n",
    "  response = lservice.documents().analyzeSentiment(\n",
    "    body={\n",
    "      'document': {\n",
    "         'type': 'PLAIN_TEXT',\n",
    "         'content': quote\n",
    "      }\n",
    "    }).execute()\n",
    "  polarity = response['documentSentiment']['polarity']\n",
    "  magnitude = response['documentSentiment']['magnitude']\n",
    "  print('POLARITY=%s MAGNITUDE=%s for %s' % (polarity, magnitude, quote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Speech API </h2>\n",
    "\n",
    "The Speech API can work on streaming data, audio content encoded and embedded directly into the POST message, or on a file on Cloud Storage. Here I'll pass in this <a href=\"https://storage.googleapis.com/cloud-training-demos/vision/audio.raw\">audio file</a> in Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'results': [{u'alternatives': [{u'confidence': 0.98267895, u'transcript': u'how old is the Brooklyn Bridge'}]}]}\n"
     ]
    }
   ],
   "source": [
    "sservice = build('speech', 'v1beta1', developerKey=APIKEY)\n",
    "response = sservice.speech().syncrecognize(\n",
    "    body={\n",
    "        'config': {\n",
    "            'encoding': 'LINEAR16',\n",
    "            'sampleRate': 16000\n",
    "        },\n",
    "        'audio': {\n",
    "            'uri': 'gs://cloud-training-demos/vision/audio.raw'\n",
    "            }\n",
    "        }).execute()\n",
    "print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how old is the Brooklyn Bridge\n",
      "Confidence=0.982679\n"
     ]
    }
   ],
   "source": [
    "print response['results'][0]['alternatives'][0]['transcript']\n",
    "print 'Confidence=%f' % response['results'][0]['alternatives'][0]['confidence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Clean up </h2>\n",
    "\n",
    "Remember to delete the API key by visiting <a href=\"http://console.cloud.google.com/apis\">API console</a>.\n",
    "\n",
    "If necessary, commit all your notebooks to git.\n",
    "\n",
    "If you are running Datalab on a Compute Engine VM or delegating to one, remember to stop or shut it down so that you are not charged.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
